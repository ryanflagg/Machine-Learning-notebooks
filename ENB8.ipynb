{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>ENB8</h1><br>\n",
    "<h2>Test automation</h2><br>\n",
    "& repeat of enb5,6 & 7 but with 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import pre_process as pp\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Pre-processing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenating files\n",
      "AReMv1\\bending1\\dataset1.csv\n",
      "AReMv1\\bending1\\dataset2.csv\n",
      "AReMv1\\bending1\\dataset3.csv\n",
      "AReMv1\\bending1\\dataset4.csv\n",
      "AReMv1\\bending1\\dataset5.csv\n",
      "AReMv1\\bending1\\dataset6.csv\n",
      "AReMv1\\bending1\\dataset7.csv\n",
      "AReMv1\\bending2\\dataset1.csv\n",
      "AReMv1\\bending2\\dataset2.csv\n",
      "AReMv1\\bending2\\dataset3.csv\n",
      "AReMv1\\bending2\\dataset5.csv\n",
      "AReMv1\\bending2\\dataset6.csv\n",
      "AReMv1\\cycling\\dataset1.csv\n",
      "AReMv1\\cycling\\dataset10.csv\n",
      "AReMv1\\cycling\\dataset11.csv\n",
      "AReMv1\\cycling\\dataset12.csv\n",
      "AReMv1\\cycling\\dataset13.csv\n",
      "AReMv1\\cycling\\dataset14.csv\n",
      "AReMv1\\cycling\\dataset15.csv\n",
      "AReMv1\\cycling\\dataset2.csv\n",
      "AReMv1\\cycling\\dataset3.csv\n",
      "AReMv1\\cycling\\dataset4.csv\n",
      "AReMv1\\cycling\\dataset5.csv\n",
      "AReMv1\\cycling\\dataset6.csv\n",
      "AReMv1\\cycling\\dataset7.csv\n",
      "AReMv1\\cycling\\dataset8.csv\n",
      "AReMv1\\cycling\\dataset9.csv\n",
      "AReMv1\\lying\\dataset1.csv\n",
      "AReMv1\\lying\\dataset10.csv\n",
      "AReMv1\\lying\\dataset11.csv\n",
      "AReMv1\\lying\\dataset12.csv\n",
      "AReMv1\\lying\\dataset13.csv\n",
      "AReMv1\\lying\\dataset14.csv\n",
      "AReMv1\\lying\\dataset15.csv\n",
      "AReMv1\\lying\\dataset2.csv\n",
      "AReMv1\\lying\\dataset3.csv\n",
      "AReMv1\\lying\\dataset4.csv\n",
      "AReMv1\\lying\\dataset5.csv\n",
      "AReMv1\\lying\\dataset6.csv\n",
      "AReMv1\\lying\\dataset7.csv\n",
      "AReMv1\\lying\\dataset8.csv\n",
      "AReMv1\\lying\\dataset9.csv\n",
      "AReMv1\\sitting\\dataset1.csv\n",
      "AReMv1\\sitting\\dataset10.csv\n",
      "AReMv1\\sitting\\dataset11.csv\n",
      "AReMv1\\sitting\\dataset12.csv\n",
      "AReMv1\\sitting\\dataset13.csv\n",
      "AReMv1\\sitting\\dataset14.csv\n",
      "AReMv1\\sitting\\dataset15.csv\n",
      "AReMv1\\sitting\\dataset2.csv\n",
      "AReMv1\\sitting\\dataset3.csv\n",
      "AReMv1\\sitting\\dataset4.csv\n",
      "AReMv1\\sitting\\dataset5.csv\n",
      "AReMv1\\sitting\\dataset6.csv\n",
      "AReMv1\\sitting\\dataset7.csv\n",
      "AReMv1\\sitting\\dataset8.csv\n",
      "AReMv1\\sitting\\dataset9.csv\n",
      "AReMv1\\standing\\dataset1.csv\n",
      "AReMv1\\standing\\dataset10.csv\n",
      "AReMv1\\standing\\dataset11.csv\n",
      "AReMv1\\standing\\dataset12.csv\n",
      "AReMv1\\standing\\dataset13.csv\n",
      "AReMv1\\standing\\dataset14.csv\n",
      "AReMv1\\standing\\dataset15.csv\n",
      "AReMv1\\standing\\dataset2.csv\n",
      "AReMv1\\standing\\dataset3.csv\n",
      "AReMv1\\standing\\dataset4.csv\n",
      "AReMv1\\standing\\dataset5.csv\n",
      "AReMv1\\standing\\dataset6.csv\n",
      "AReMv1\\standing\\dataset7.csv\n",
      "AReMv1\\standing\\dataset8.csv\n",
      "AReMv1\\standing\\dataset9.csv\n",
      "AReMv1\\walking\\dataset1.csv\n",
      "AReMv1\\walking\\dataset10.csv\n",
      "AReMv1\\walking\\dataset11.csv\n",
      "AReMv1\\walking\\dataset12.csv\n",
      "AReMv1\\walking\\dataset13.csv\n",
      "AReMv1\\walking\\dataset14.csv\n",
      "AReMv1\\walking\\dataset15.csv\n",
      "AReMv1\\walking\\dataset2.csv\n",
      "AReMv1\\walking\\dataset3.csv\n",
      "AReMv1\\walking\\dataset4.csv\n",
      "AReMv1\\walking\\dataset5.csv\n",
      "AReMv1\\walking\\dataset6.csv\n",
      "AReMv1\\walking\\dataset7.csv\n",
      "AReMv1\\walking\\dataset8.csv\n",
      "AReMv1\\walking\\dataset9.csv\n",
      "Tokenising labels\n",
      "bending1 = 0\n",
      "bending1 = 0\n",
      "bending1 = 0\n",
      "bending1 = 0\n",
      "bending1 = 0\n",
      "bending1 = 0\n",
      "bending1 = 0\n",
      "bending2 = 1\n",
      "bending2 = 1\n",
      "bending2 = 1\n",
      "bending2 = 1\n",
      "bending2 = 1\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "data shape:\n",
      "(87, 480, 6)\n",
      "labels shape:\n",
      "(87,)\n"
     ]
    }
   ],
   "source": [
    "data, labels = pp.pre_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHUFFLING ARRAYS\n",
      "act0 shape:  (7, 480, 6)\n",
      "act1 shape:  (5, 480, 6)\n",
      "act2 shape:  (15, 480, 6)\n",
      "act3 shape:  (15, 480, 6)\n",
      "act4 shape:  (15, 480, 6)\n",
      "act5 shape:  (15, 480, 6)\n",
      "act6 shape:  (15, 480, 6)\n",
      "SLICING ARRAYS\n",
      "(4, 480, 6)\n",
      "(2, 480, 6)\n",
      "(1, 480, 6)\n"
     ]
    }
   ],
   "source": [
    "#train_data, train_labels, val_data, val_labels, test_data, test_labels = pp.cluster_shuffle(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exp:7a</h2><br>\n",
    "1 layer, 720 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 480, 480)          3360      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 480, 720)          346320    \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 345600)            0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 7)                 2419207   \n",
      "=================================================================\n",
      "Total params: 2,768,887\n",
      "Trainable params: 2,768,887\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net1 = models.Sequential()\n",
    "net1.add(layers.Dense(480, input_shape = (480,6)))\n",
    "net1.add(layers.Dense (720, activation = 'relu'))\n",
    "net1.add(layers.Flatten())\n",
    "net1.add(layers.Dense(7, activation = 'sigmoid'))\n",
    "net1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test1(test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels):    \n",
    "    net1.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    hist1 = net1.fit(train_data, train_labels, epochs = 5, validation_data = (val_data, val_labels))\n",
    "    test_results = net1.evaluate(test_data, test_labels)\n",
    "    test_results.insert(0,'720')\n",
    "    test_results.insert(1,test_no)\n",
    "    test_no = test_no + 1\n",
    "    summary = []\n",
    "    summary.append(test_results)\n",
    "    return test_no, summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exp:7b</h2><br>\n",
    "1layer 600 nuerons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 480, 480)          3360      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 480, 600)          288600    \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 288000)            0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 7)                 2016007   \n",
      "=================================================================\n",
      "Total params: 2,307,967\n",
      "Trainable params: 2,307,967\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net2 = models.Sequential()\n",
    "net2.add(layers.Dense(480, input_shape = (480,6)))\n",
    "net2.add(layers.Dense (600, activation = 'relu'))\n",
    "net2.add(layers.Flatten())\n",
    "net2.add(layers.Dense(7, activation = 'sigmoid'))\n",
    "net2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test2(test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels):\n",
    "    net2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    hist2 = net2.fit(train_data, train_labels, epochs = 5, validation_data = (val_data, val_labels))\n",
    "    test_results = net2.evaluate(test_data, test_labels)\n",
    "    test_results.insert(0,'600')\n",
    "    test_results.insert(1,test_no)\n",
    "    test_no = test_no + 1\n",
    "    summary = []\n",
    "    summary.append(test_results)\n",
    "    return test_no, summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exp:7c</h2><br>\n",
    "1 layer 480 nuerons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 480, 480)          3360      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 480, 480)          230880    \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 230400)            0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 7)                 1612807   \n",
      "=================================================================\n",
      "Total params: 1,847,047\n",
      "Trainable params: 1,847,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net3 = models.Sequential()\n",
    "net3.add(layers.Dense(480, input_shape = (480,6)))\n",
    "net3.add(layers.Dense (480, activation = 'relu'))\n",
    "net3.add(layers.Flatten())\n",
    "net3.add(layers.Dense(7, activation = 'sigmoid'))\n",
    "net3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test3(test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels):\n",
    "    net3.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    hist3 = net3.fit(train_data, train_labels, epochs = 5, validation_data = (val_data, val_labels))\n",
    "    test_results = net3.evaluate(test_data, test_labels)\n",
    "    test_results.insert(0,'480')\n",
    "    test_results.insert(1,test_no)\n",
    "    test_no = test_no + 1\n",
    "    summary = []\n",
    "    summary.append(test_results)\n",
    "    return test_no, summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exp:7d</h2>\n",
    "<br>\n",
    "1 layer 360 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 480, 480)          3360      \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 480, 360)          173160    \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 172800)            0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 7)                 1209607   \n",
      "=================================================================\n",
      "Total params: 1,386,127\n",
      "Trainable params: 1,386,127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net4 = models.Sequential()\n",
    "net4.add(layers.Dense(480, input_shape = (480,6)))\n",
    "net4.add(layers.Dense (360, activation = 'relu'))\n",
    "net4.add(layers.Flatten())\n",
    "net4.add(layers.Dense(7, activation = 'sigmoid'))\n",
    "net4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test4(test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels):\n",
    "    net4.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    hist4 = net4.fit(train_data, train_labels, epochs = 5, validation_data = (val_data, val_labels))\n",
    "    test_results = net4.evaluate(test_data, test_labels)\n",
    "    test_results.insert(0,'360')\n",
    "    test_results.insert(1,test_no)\n",
    "    test_no = test_no + 1\n",
    "    summary = []\n",
    "    summary.append(test_results)\n",
    "    return test_no, summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exp:7e</h2><br>\n",
    "1 layer 240 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 480, 480)          3360      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 480, 240)          115440    \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 115200)            0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 7)                 806407    \n",
      "=================================================================\n",
      "Total params: 925,207\n",
      "Trainable params: 925,207\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net5 = models.Sequential()\n",
    "net5.add(layers.Dense(480, input_shape = (480,6)))\n",
    "net5.add(layers.Dense (240, activation = 'relu'))\n",
    "net5.add(layers.Flatten())\n",
    "net5.add(layers.Dense(7, activation = 'sigmoid'))\n",
    "net5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test5(test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels):\n",
    "    net5.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    hist5 = net5.fit(train_data, train_labels, epochs = 5, validation_data = (val_data, val_labels))\n",
    "    test_results = net5.evaluate(test_data, test_labels)\n",
    "    test_results.insert(0,'240')\n",
    "    test_results.insert(1,test_no)\n",
    "    test_no = test_no + 1\n",
    "    summary = []\n",
    "    summary.append(test_results)\n",
    "    return test_no, summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exp:7f</h2>\n",
    "<br>\n",
    "1 layer 120 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 480, 480)          3360      \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 480, 120)          57720     \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 7)                 403207    \n",
      "=================================================================\n",
      "Total params: 464,287\n",
      "Trainable params: 464,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net6 = models.Sequential()\n",
    "net6.add(layers.Dense(480, input_shape = (480,6)))\n",
    "net6.add(layers.Dense (120, activation = 'relu'))\n",
    "net6.add(layers.Flatten())\n",
    "net6.add(layers.Dense(7, activation = 'sigmoid'))\n",
    "net6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test6(test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels):\n",
    "    net6.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    hist6 = net6.fit(train_data, train_labels, epochs = 5, validation_data = (val_data, val_labels))\n",
    "    test_results = net6.evaluate(test_data, test_labels)\n",
    "    test_results.insert(0,'120')\n",
    "    test_results.insert(1,test_no)\n",
    "    test_no = test_no + 1\n",
    "    summary = []\n",
    "    summary.append(test_results)\n",
    "    return test_no, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(data, labels):\n",
    "    start = time.time()\n",
    "    summary = []\n",
    "    i = 1\n",
    "    test_no = 1\n",
    "    while i < 6:\n",
    "        train_data, train_labels, val_data, val_labels, test_data, test_labels = pp.cluster_shuffle(data, labels)\n",
    "        test_no, summary1 = train_test1(test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "        test_no, summary2 = train_test2(test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "        test_no, summary3 = train_test3(test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "        test_no, summary4 = train_test4(test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "        test_no, summary5 = train_test5(test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "        test_no, summary6 = train_test6(test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "        summary = summary + summary1 + summary2 + summary3 + summary4 + summary5 + summary6\n",
    "        i = i + 1 \n",
    "    print(summary)\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print('Time elapsed: ', elapsed)\n",
    "    with open('ENB8_results2.txt', 'wb') as fp:\n",
    "        pickle.dump(summary, fp)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHUFFLING ARRAYS\n",
      "act0 shape:  (7, 480, 6)\n",
      "act1 shape:  (5, 480, 6)\n",
      "act2 shape:  (15, 480, 6)\n",
      "act3 shape:  (15, 480, 6)\n",
      "act4 shape:  (15, 480, 6)\n",
      "act5 shape:  (15, 480, 6)\n",
      "act6 shape:  (15, 480, 6)\n",
      "SLICING ARRAYS\n",
      "(4, 480, 6)\n",
      "(2, 480, 6)\n",
      "(1, 480, 6)\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 2.5472 - accuracy: 0.1538 - val_loss: 2.0804 - val_accuracy: 0.1667\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.9944 - accuracy: 0.1923 - val_loss: 1.6737 - val_accuracy: 0.1667\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.6103 - accuracy: 0.2692 - val_loss: 1.4677 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 1.3987 - accuracy: 0.4038 - val_loss: 1.1071 - val_accuracy: 0.5556\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.1099 - accuracy: 0.5385 - val_loss: 1.0610 - val_accuracy: 0.5000\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 2.2841 - accuracy: 0.0962 - val_loss: 1.8730 - val_accuracy: 0.1667\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 1.8039 - accuracy: 0.2115 - val_loss: 1.7020 - val_accuracy: 0.1667\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.6564 - accuracy: 0.3269 - val_loss: 1.5017 - val_accuracy: 0.2778\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.4482 - accuracy: 0.4038 - val_loss: 1.2946 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 1.1616 - accuracy: 0.5192 - val_loss: 1.3073 - val_accuracy: 0.3889\n",
      "17/17 [==============================] - 0s 4ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 2.1174 - accuracy: 0.0769 - val_loss: 1.8762 - val_accuracy: 0.2222\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.7974 - accuracy: 0.3077 - val_loss: 1.8082 - val_accuracy: 0.3333\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.7271 - accuracy: 0.4038 - val_loss: 1.4857 - val_accuracy: 0.4444\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.4129 - accuracy: 0.5000 - val_loss: 1.3144 - val_accuracy: 0.3333\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2009 - accuracy: 0.4038 - val_loss: 1.0182 - val_accuracy: 0.5000\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 2.1849 - accuracy: 0.1346 - val_loss: 1.8618 - val_accuracy: 0.2778\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.8123 - accuracy: 0.3462 - val_loss: 1.6657 - val_accuracy: 0.3333\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.6242 - accuracy: 0.3462 - val_loss: 1.4734 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3191 - accuracy: 0.5385 - val_loss: 1.1790 - val_accuracy: 0.5556\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.0887 - accuracy: 0.5577 - val_loss: 1.0785 - val_accuracy: 0.4444\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 2.0798 - accuracy: 0.2115 - val_loss: 1.8163 - val_accuracy: 0.1667\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.7765 - accuracy: 0.2308 - val_loss: 1.6643 - val_accuracy: 0.1667\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.6114 - accuracy: 0.1731 - val_loss: 1.5685 - val_accuracy: 0.1667\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.5074 - accuracy: 0.1731 - val_loss: 1.4518 - val_accuracy: 0.2778\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3440 - accuracy: 0.2692 - val_loss: 1.3020 - val_accuracy: 0.3889\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 1s 29ms/step - loss: 1.9906 - accuracy: 0.0962 - val_loss: 1.8421 - val_accuracy: 0.1667\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.7952 - accuracy: 0.1923 - val_loss: 1.7248 - val_accuracy: 0.2778\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.6488 - accuracy: 0.3269 - val_loss: 1.5005 - val_accuracy: 0.2222\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.4702 - accuracy: 0.3269 - val_loss: 1.3098 - val_accuracy: 0.3889\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.2015 - accuracy: 0.5385 - val_loss: 1.2101 - val_accuracy: 0.6111\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "SHUFFLING ARRAYS\n",
      "act0 shape:  (7, 480, 6)\n",
      "act1 shape:  (5, 480, 6)\n",
      "act2 shape:  (15, 480, 6)\n",
      "act3 shape:  (15, 480, 6)\n",
      "act4 shape:  (15, 480, 6)\n",
      "act5 shape:  (15, 480, 6)\n",
      "act6 shape:  (15, 480, 6)\n",
      "SLICING ARRAYS\n",
      "(4, 480, 6)\n",
      "(2, 480, 6)\n",
      "(1, 480, 6)\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 37ms/step - loss: 2.1038 - accuracy: 0.4231 - val_loss: 1.5510 - val_accuracy: 0.2778\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 1.1934 - accuracy: 0.5000 - val_loss: 1.5021 - val_accuracy: 0.2222\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.3476 - accuracy: 0.4615 - val_loss: 1.2572 - val_accuracy: 0.4444\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.1319 - accuracy: 0.5192 - val_loss: 1.3215 - val_accuracy: 0.5556\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.1142 - accuracy: 0.5000 - val_loss: 1.0575 - val_accuracy: 0.6111\n",
      "17/17 [==============================] - 0s 5ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 1.5703 - accuracy: 0.4615 - val_loss: 1.0460 - val_accuracy: 0.6667\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.4047 - accuracy: 0.5192 - val_loss: 1.8527 - val_accuracy: 0.3889\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.4525 - accuracy: 0.4038 - val_loss: 1.1641 - val_accuracy: 0.3333\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.9740 - accuracy: 0.4423 - val_loss: 1.1577 - val_accuracy: 0.2778\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.9653 - accuracy: 0.4423 - val_loss: 0.9982 - val_accuracy: 0.6111\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 2.0550 - accuracy: 0.4808 - val_loss: 0.9287 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 0.9923 - accuracy: 0.4808 - val_loss: 1.7777 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3253 - accuracy: 0.5769 - val_loss: 1.1278 - val_accuracy: 0.5556\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.0394 - accuracy: 0.5577 - val_loss: 1.4047 - val_accuracy: 0.1667\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.1479 - accuracy: 0.2500 - val_loss: 1.1566 - val_accuracy: 0.5000\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 1.5759 - accuracy: 0.5000 - val_loss: 1.2735 - val_accuracy: 0.6667\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3454 - accuracy: 0.5000 - val_loss: 1.3261 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 0.9981 - accuracy: 0.5000 - val_loss: 1.2053 - val_accuracy: 0.4444\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 5ms/step - loss: 0.9650 - accuracy: 0.5192 - val_loss: 1.0795 - val_accuracy: 0.5556\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.8996 - accuracy: 0.6154 - val_loss: 0.9364 - val_accuracy: 0.6111\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 1.4098 - accuracy: 0.3846 - val_loss: 1.3613 - val_accuracy: 0.3333\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.1751 - accuracy: 0.3846 - val_loss: 1.0695 - val_accuracy: 0.5556\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.0330 - accuracy: 0.5769 - val_loss: 1.0966 - val_accuracy: 0.3889\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.0081 - accuracy: 0.4231 - val_loss: 1.0706 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.8209 - accuracy: 0.6538 - val_loss: 1.0654 - val_accuracy: 0.4444\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 1.4923 - accuracy: 0.6154 - val_loss: 1.2431 - val_accuracy: 0.3333\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.1816 - accuracy: 0.3462 - val_loss: 1.4065 - val_accuracy: 0.3889\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.2147 - accuracy: 0.5769 - val_loss: 1.2185 - val_accuracy: 0.5556\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9844 - accuracy: 0.5577 - val_loss: 1.3414 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.0093 - accuracy: 0.4808 - val_loss: 1.1354 - val_accuracy: 0.4444\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "SHUFFLING ARRAYS\n",
      "act0 shape:  (7, 480, 6)\n",
      "act1 shape:  (5, 480, 6)\n",
      "act2 shape:  (15, 480, 6)\n",
      "act3 shape:  (15, 480, 6)\n",
      "act4 shape:  (15, 480, 6)\n",
      "act5 shape:  (15, 480, 6)\n",
      "act6 shape:  (15, 480, 6)\n",
      "SLICING ARRAYS\n",
      "(4, 480, 6)\n",
      "(2, 480, 6)\n",
      "(1, 480, 6)\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 1.2875 - accuracy: 0.5769 - val_loss: 0.9956 - val_accuracy: 0.7778\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.8156 - accuracy: 0.5769 - val_loss: 1.0769 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.6731 - accuracy: 0.6346 - val_loss: 1.0279 - val_accuracy: 0.7778\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4390 - accuracy: 0.8846 - val_loss: 1.0731 - val_accuracy: 0.5556\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.4087 - accuracy: 0.8462 - val_loss: 0.8259 - val_accuracy: 0.7778\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 1.2663 - accuracy: 0.4231 - val_loss: 0.8276 - val_accuracy: 0.6667\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.7917 - accuracy: 0.6731 - val_loss: 1.0298 - val_accuracy: 0.4444\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.8331 - accuracy: 0.5577 - val_loss: 0.7546 - val_accuracy: 0.7778\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5500 - accuracy: 0.8654 - val_loss: 0.7996 - val_accuracy: 0.7222\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.4189 - accuracy: 0.8269 - val_loss: 0.9693 - val_accuracy: 0.8333\n",
      "17/17 [==============================] - 0s 4ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 1.5289 - accuracy: 0.4231 - val_loss: 1.0303 - val_accuracy: 0.5556\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 0.9265 - accuracy: 0.7500 - val_loss: 1.6089 - val_accuracy: 0.4444\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3658 - accuracy: 0.5192 - val_loss: 1.0139 - val_accuracy: 0.7778\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 0.7067 - accuracy: 0.7692 - val_loss: 1.0855 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.7532 - accuracy: 0.7308 - val_loss: 1.0017 - val_accuracy: 0.6667\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 1.1207 - accuracy: 0.5192 - val_loss: 1.0353 - val_accuracy: 0.6111\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 0.9166 - accuracy: 0.6538 - val_loss: 1.1173 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.7984 - accuracy: 0.6346 - val_loss: 1.1440 - val_accuracy: 0.6667\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.7276 - accuracy: 0.6731 - val_loss: 0.9764 - val_accuracy: 0.6667\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 0.5312 - accuracy: 0.8077 - val_loss: 0.8119 - val_accuracy: 0.6111\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 1.4193 - accuracy: 0.3654 - val_loss: 0.8199 - val_accuracy: 0.6667\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.7779 - accuracy: 0.7308 - val_loss: 1.0830 - val_accuracy: 0.5556\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.8726 - accuracy: 0.5962 - val_loss: 0.9642 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6159 - accuracy: 0.8846 - val_loss: 0.8218 - val_accuracy: 0.7778\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.8077 - val_loss: 0.8329 - val_accuracy: 0.6111\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 1.0498 - accuracy: 0.6154 - val_loss: 1.2170 - val_accuracy: 0.5556\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8651 - accuracy: 0.6346 - val_loss: 1.0819 - val_accuracy: 0.5556\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9352 - accuracy: 0.5769 - val_loss: 0.8734 - val_accuracy: 0.6667\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.8654 - val_loss: 0.9877 - val_accuracy: 0.6667\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5678 - accuracy: 0.7885 - val_loss: 0.8970 - val_accuracy: 0.5556\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "SHUFFLING ARRAYS\n",
      "act0 shape:  (7, 480, 6)\n",
      "act1 shape:  (5, 480, 6)\n",
      "act2 shape:  (15, 480, 6)\n",
      "act3 shape:  (15, 480, 6)\n",
      "act4 shape:  (15, 480, 6)\n",
      "act5 shape:  (15, 480, 6)\n",
      "act6 shape:  (15, 480, 6)\n",
      "SLICING ARRAYS\n",
      "(4, 480, 6)\n",
      "(2, 480, 6)\n",
      "(1, 480, 6)\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.9113 - accuracy: 0.7885 - val_loss: 1.7408 - val_accuracy: 0.5556\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 1.5666 - accuracy: 0.5192 - val_loss: 0.9401 - val_accuracy: 0.6667\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5983 - accuracy: 0.8077 - val_loss: 0.3657 - val_accuracy: 0.8333\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.4897 - accuracy: 0.8462 - val_loss: 0.4942 - val_accuracy: 0.7778\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5674 - accuracy: 0.7885 - val_loss: 0.5203 - val_accuracy: 0.8889\n",
      "17/17 [==============================] - 0s 4ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 1.6312 - accuracy: 0.6731 - val_loss: 0.4671 - val_accuracy: 0.8889\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 9ms/step - loss: 0.5823 - accuracy: 0.7500 - val_loss: 0.7652 - val_accuracy: 0.5556\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 1.0017 - accuracy: 0.6154 - val_loss: 0.5054 - val_accuracy: 0.8333\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5735 - accuracy: 0.8462 - val_loss: 0.4006 - val_accuracy: 0.8889\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.4896 - accuracy: 0.8269 - val_loss: 0.5474 - val_accuracy: 0.8333\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 1.2198 - accuracy: 0.5962 - val_loss: 0.5111 - val_accuracy: 0.7778\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 0.4401 - accuracy: 0.9038 - val_loss: 1.1089 - val_accuracy: 0.7778\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.0573 - accuracy: 0.6731 - val_loss: 0.5533 - val_accuracy: 0.7222\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.3501 - accuracy: 0.9231 - val_loss: 0.5713 - val_accuracy: 0.7778\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.7692 - val_loss: 0.3817 - val_accuracy: 0.8889\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 37ms/step - loss: 0.8437 - accuracy: 0.6923 - val_loss: 0.5941 - val_accuracy: 0.8333\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 0.6889 - accuracy: 0.7692 - val_loss: 0.8360 - val_accuracy: 0.7222\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 0.6892 - accuracy: 0.7692 - val_loss: 0.4660 - val_accuracy: 0.8333\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3291 - accuracy: 0.9231 - val_loss: 0.5132 - val_accuracy: 0.8889\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 0.4496 - accuracy: 0.8462 - val_loss: 0.4633 - val_accuracy: 0.7778\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 1.3228 - accuracy: 0.5769 - val_loss: 0.6096 - val_accuracy: 0.7222\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6552 - accuracy: 0.6923 - val_loss: 0.8729 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.7902 - accuracy: 0.6346 - val_loss: 0.5244 - val_accuracy: 0.7222\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5513 - accuracy: 0.7885 - val_loss: 0.4827 - val_accuracy: 0.8333\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.8269 - val_loss: 0.5277 - val_accuracy: 0.7778\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 0.8101 - accuracy: 0.6538 - val_loss: 0.9050 - val_accuracy: 0.6667\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7995 - accuracy: 0.6923 - val_loss: 0.5581 - val_accuracy: 0.6111\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6804 - accuracy: 0.6538 - val_loss: 0.7160 - val_accuracy: 0.6111\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.7308 - val_loss: 0.4975 - val_accuracy: 0.8333\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.9423 - val_loss: 0.4134 - val_accuracy: 0.9444\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "SHUFFLING ARRAYS\n",
      "act0 shape:  (7, 480, 6)\n",
      "act1 shape:  (5, 480, 6)\n",
      "act2 shape:  (15, 480, 6)\n",
      "act3 shape:  (15, 480, 6)\n",
      "act4 shape:  (15, 480, 6)\n",
      "act5 shape:  (15, 480, 6)\n",
      "act6 shape:  (15, 480, 6)\n",
      "SLICING ARRAYS\n",
      "(4, 480, 6)\n",
      "(2, 480, 6)\n",
      "(1, 480, 6)\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 0.7936 - accuracy: 0.7115 - val_loss: 0.2310 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.3665 - accuracy: 0.9038 - val_loss: 0.3597 - val_accuracy: 0.8889\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.2628 - accuracy: 0.9615 - val_loss: 0.2003 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.1299 - accuracy: 0.9615 - val_loss: 0.2427 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.1136 - accuracy: 0.9808 - val_loss: 0.3142 - val_accuracy: 0.9444\n",
      "17/17 [==============================] - 0s 5ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 0.5196 - accuracy: 0.8654 - val_loss: 0.6826 - val_accuracy: 0.7778\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.2548 - accuracy: 0.9615 - val_loss: 0.3967 - val_accuracy: 0.7778\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.3767 - accuracy: 0.9231 - val_loss: 0.2816 - val_accuracy: 0.8889\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.1124 - accuracy: 0.9808 - val_loss: 0.2320 - val_accuracy: 0.8333\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.1089 - accuracy: 0.9615 - val_loss: 0.4143 - val_accuracy: 0.8333\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.4473 - accuracy: 0.8654 - val_loss: 0.4607 - val_accuracy: 0.7222\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 0.2294 - accuracy: 0.9231 - val_loss: 0.3652 - val_accuracy: 0.7778\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 0.3000 - accuracy: 0.8462 - val_loss: 0.2271 - val_accuracy: 0.8889\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 0.1397 - accuracy: 0.9615 - val_loss: 0.2883 - val_accuracy: 0.8333\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 0.0689 - accuracy: 0.9808 - val_loss: 0.1137 - val_accuracy: 1.0000\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 37ms/step - loss: 0.4796 - accuracy: 0.7500 - val_loss: 0.2804 - val_accuracy: 0.9444\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.2877 - accuracy: 0.9231 - val_loss: 0.3986 - val_accuracy: 0.7778\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.2105 - accuracy: 0.9423 - val_loss: 0.4437 - val_accuracy: 0.8333\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 0.1950 - accuracy: 0.9808 - val_loss: 0.3661 - val_accuracy: 0.8333\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.1100 - accuracy: 0.9808 - val_loss: 0.2281 - val_accuracy: 0.9444\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 0.9742 - accuracy: 0.6346 - val_loss: 0.5635 - val_accuracy: 0.8889\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.8654 - val_loss: 0.5935 - val_accuracy: 0.6111\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5999 - accuracy: 0.7115 - val_loss: 0.4030 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3202 - accuracy: 0.9615 - val_loss: 0.3709 - val_accuracy: 0.9444\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.2495 - accuracy: 0.9038 - val_loss: 0.3618 - val_accuracy: 0.8889\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 0.4333 - accuracy: 0.8269 - val_loss: 0.3116 - val_accuracy: 0.9444\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 3ms/step - loss: 0.2934 - accuracy: 0.8654 - val_loss: 0.8380 - val_accuracy: 0.7222\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.8462 - val_loss: 0.2255 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.1778 - accuracy: 0.9615 - val_loss: 0.3682 - val_accuracy: 0.8333\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.2678 - accuracy: 0.8846 - val_loss: 0.1996 - val_accuracy: 1.0000\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "[['720', 1, 1.2636327743530273, 0.47058823704719543], ['600', 2, 1.2720838785171509, 0.3529411852359772], ['480', 3, 1.1117148399353027, 0.47058823704719543], ['360', 4, 1.2283135652542114, 0.529411792755127], ['240', 5, 1.370044231414795, 0.4117647111415863], ['120', 6, 1.2445331811904907, 0.7647058963775635], ['720', 7, 1.2014245986938477, 0.47058823704719543], ['600', 8, 1.2649590969085693, 0.47058823704719543], ['480', 9, 1.3625476360321045, 0.529411792755127], ['360', 10, 1.083601713180542, 0.47058823704719543], ['240', 11, 1.3122332096099854, 0.3529411852359772], ['120', 12, 1.241325855255127, 0.3529411852359772], ['720', 13, 0.3989560008049011, 0.9411764740943909], ['600', 14, 0.544130802154541, 0.7647058963775635], ['480', 15, 0.6868698000907898, 0.7647058963775635], ['360', 16, 0.6952919960021973, 0.6470588445663452], ['240', 17, 0.7117906808853149, 0.6470588445663452], ['120', 18, 0.6238822340965271, 0.7058823704719543], ['720', 19, 0.532745361328125, 0.9411764740943909], ['600', 20, 0.5064980983734131, 0.8235294222831726], ['480', 21, 0.37041833996772766, 0.9411764740943909], ['360', 22, 0.47812849283218384, 0.8235294222831726], ['240', 23, 0.4927535355091095, 0.7647058963775635], ['120', 24, 0.4478909969329834, 0.9411764740943909], ['720', 25, 0.5184420347213745, 0.8823529481887817], ['600', 26, 0.7567643523216248, 0.7058823704719543], ['480', 27, 0.4351189136505127, 0.8823529481887817], ['360', 28, 0.4055256247520447, 0.8823529481887817], ['240', 29, 0.465680330991745, 0.8235294222831726], ['120', 30, 0.3856047987937927, 0.8823529481887817]]\n",
      "Time elapsed:  251.34064245224\n"
     ]
    }
   ],
   "source": [
    "summary = start(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
