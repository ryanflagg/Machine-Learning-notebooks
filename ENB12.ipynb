{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>ENB12</h1><br>\n",
    "<h2>dual layer feedforard ANNs, softmax and 100 epochs</h2><br>\n",
    "neurons = 720, 600, 480, 360, 240, 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryan\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Ryan\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Ryan\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Ryan\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Ryan\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Ryan\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Ryan\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Ryan\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Ryan\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Ryan\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Ryan\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Ryan\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import pre_process as pp\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Pre-processing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenating files\n",
      "AReMv1\\bending1\\dataset1.csv\n",
      "AReMv1\\bending1\\dataset2.csv\n",
      "AReMv1\\bending1\\dataset3.csv\n",
      "AReMv1\\bending1\\dataset4.csv\n",
      "AReMv1\\bending1\\dataset5.csv\n",
      "AReMv1\\bending1\\dataset6.csv\n",
      "AReMv1\\bending1\\dataset7.csv\n",
      "AReMv1\\bending2\\dataset1.csv\n",
      "AReMv1\\bending2\\dataset2.csv\n",
      "AReMv1\\bending2\\dataset3.csv\n",
      "AReMv1\\bending2\\dataset5.csv\n",
      "AReMv1\\bending2\\dataset6.csv\n",
      "AReMv1\\cycling\\dataset1.csv\n",
      "AReMv1\\cycling\\dataset10.csv\n",
      "AReMv1\\cycling\\dataset11.csv\n",
      "AReMv1\\cycling\\dataset12.csv\n",
      "AReMv1\\cycling\\dataset13.csv\n",
      "AReMv1\\cycling\\dataset14.csv\n",
      "AReMv1\\cycling\\dataset15.csv\n",
      "AReMv1\\cycling\\dataset2.csv\n",
      "AReMv1\\cycling\\dataset3.csv\n",
      "AReMv1\\cycling\\dataset4.csv\n",
      "AReMv1\\cycling\\dataset5.csv\n",
      "AReMv1\\cycling\\dataset6.csv\n",
      "AReMv1\\cycling\\dataset7.csv\n",
      "AReMv1\\cycling\\dataset8.csv\n",
      "AReMv1\\cycling\\dataset9.csv\n",
      "AReMv1\\lying\\dataset1.csv\n",
      "AReMv1\\lying\\dataset10.csv\n",
      "AReMv1\\lying\\dataset11.csv\n",
      "AReMv1\\lying\\dataset12.csv\n",
      "AReMv1\\lying\\dataset13.csv\n",
      "AReMv1\\lying\\dataset14.csv\n",
      "AReMv1\\lying\\dataset15.csv\n",
      "AReMv1\\lying\\dataset2.csv\n",
      "AReMv1\\lying\\dataset3.csv\n",
      "AReMv1\\lying\\dataset4.csv\n",
      "AReMv1\\lying\\dataset5.csv\n",
      "AReMv1\\lying\\dataset6.csv\n",
      "AReMv1\\lying\\dataset7.csv\n",
      "AReMv1\\lying\\dataset8.csv\n",
      "AReMv1\\lying\\dataset9.csv\n",
      "AReMv1\\sitting\\dataset1.csv\n",
      "AReMv1\\sitting\\dataset10.csv\n",
      "AReMv1\\sitting\\dataset11.csv\n",
      "AReMv1\\sitting\\dataset12.csv\n",
      "AReMv1\\sitting\\dataset13.csv\n",
      "AReMv1\\sitting\\dataset14.csv\n",
      "AReMv1\\sitting\\dataset15.csv\n",
      "AReMv1\\sitting\\dataset2.csv\n",
      "AReMv1\\sitting\\dataset3.csv\n",
      "AReMv1\\sitting\\dataset4.csv\n",
      "AReMv1\\sitting\\dataset5.csv\n",
      "AReMv1\\sitting\\dataset6.csv\n",
      "AReMv1\\sitting\\dataset7.csv\n",
      "AReMv1\\sitting\\dataset8.csv\n",
      "AReMv1\\sitting\\dataset9.csv\n",
      "AReMv1\\standing\\dataset1.csv\n",
      "AReMv1\\standing\\dataset10.csv\n",
      "AReMv1\\standing\\dataset11.csv\n",
      "AReMv1\\standing\\dataset12.csv\n",
      "AReMv1\\standing\\dataset13.csv\n",
      "AReMv1\\standing\\dataset14.csv\n",
      "AReMv1\\standing\\dataset15.csv\n",
      "AReMv1\\standing\\dataset2.csv\n",
      "AReMv1\\standing\\dataset3.csv\n",
      "AReMv1\\standing\\dataset4.csv\n",
      "AReMv1\\standing\\dataset5.csv\n",
      "AReMv1\\standing\\dataset6.csv\n",
      "AReMv1\\standing\\dataset7.csv\n",
      "AReMv1\\standing\\dataset8.csv\n",
      "AReMv1\\standing\\dataset9.csv\n",
      "AReMv1\\walking\\dataset1.csv\n",
      "AReMv1\\walking\\dataset10.csv\n",
      "AReMv1\\walking\\dataset11.csv\n",
      "AReMv1\\walking\\dataset12.csv\n",
      "AReMv1\\walking\\dataset13.csv\n",
      "AReMv1\\walking\\dataset14.csv\n",
      "AReMv1\\walking\\dataset15.csv\n",
      "AReMv1\\walking\\dataset2.csv\n",
      "AReMv1\\walking\\dataset3.csv\n",
      "AReMv1\\walking\\dataset4.csv\n",
      "AReMv1\\walking\\dataset5.csv\n",
      "AReMv1\\walking\\dataset6.csv\n",
      "AReMv1\\walking\\dataset7.csv\n",
      "AReMv1\\walking\\dataset8.csv\n",
      "AReMv1\\walking\\dataset9.csv\n",
      "Tokenising labels\n",
      "bending1 = 0\n",
      "bending1 = 0\n",
      "bending1 = 0\n",
      "bending1 = 0\n",
      "bending1 = 0\n",
      "bending1 = 0\n",
      "bending1 = 0\n",
      "bending2 = 1\n",
      "bending2 = 1\n",
      "bending2 = 1\n",
      "bending2 = 1\n",
      "bending2 = 1\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "cycling = 2\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "lying = 3\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "sitting = 4\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "standing = 5\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "walking = 6\n",
      "data shape:\n",
      "(87, 480, 6)\n",
      "labels shape:\n",
      "(87,)\n"
     ]
    }
   ],
   "source": [
    "data, labels = pp.pre_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exp:a</h2><br>\n",
    "2 layer, 720 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_net1():\n",
    "    net1 = models.Sequential()\n",
    "    net1.add(layers.Dense(480, input_shape = (480,6)))\n",
    "    net1.add(layers.Dense (720, activation = 'softmax'))\n",
    "    net1.add(layers.Dense (720, activation = 'softmax'))\n",
    "    net1.add(layers.Flatten())\n",
    "    net1.add(layers.Dense(7, activation = 'sigmoid'))\n",
    "    net1.summary()\n",
    "    return net1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test1(net, test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels):    \n",
    "    net.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    hist = net.fit(train_data, train_labels, epochs = 100, validation_data = (val_data, val_labels))\n",
    "    test_results = net.evaluate(test_data, test_labels)\n",
    "    test_results.insert(0,'720,720')\n",
    "    test_results.insert(1,test_no)\n",
    "    test_no = test_no + 1\n",
    "    summary = []\n",
    "    summary.append(test_results)\n",
    "    return test_no, summary, hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exp:b</h2><br>\n",
    "2layer 600 nuerons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_net2():\n",
    "    net1 = models.Sequential()\n",
    "    net1.add(layers.Dense(480, input_shape = (480,6)))\n",
    "    net1.add(layers.Dense (600, activation = 'softmax'))\n",
    "    net1.add(layers.Dense (600, activation = 'softmax'))\n",
    "    net1.add(layers.Flatten())\n",
    "    net1.add(layers.Dense(7, activation = 'sigmoid'))\n",
    "    net1.summary()\n",
    "    return net1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test2(net, test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels):\n",
    "    net.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    hist = net.fit(train_data, train_labels, epochs = 100, validation_data = (val_data, val_labels))\n",
    "    test_results = net.evaluate(test_data, test_labels)\n",
    "    test_results.insert(0,'600,600')\n",
    "    test_results.insert(1,test_no)\n",
    "    test_no = test_no + 1\n",
    "    summary = []\n",
    "    summary.append(test_results)\n",
    "    return test_no, summary, hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exp:c</h2><br>\n",
    "2layer 480 nuerons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_net3():\n",
    "    net1 = models.Sequential()\n",
    "    net1.add(layers.Dense(480, input_shape = (480,6)))\n",
    "    net1.add(layers.Dense (480, activation = 'softmax'))\n",
    "    net1.add(layers.Dense (480, activation = 'softmax'))\n",
    "    net1.add(layers.Flatten())\n",
    "    net1.add(layers.Dense(7, activation = 'sigmoid'))\n",
    "    net1.summary()\n",
    "    return net1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test3(net, test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels):\n",
    "    net.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    hist = net.fit(train_data, train_labels, epochs = 100, validation_data = (val_data, val_labels))\n",
    "    test_results = net.evaluate(test_data, test_labels)\n",
    "    test_results.insert(0,'480,480')\n",
    "    test_results.insert(1,test_no)\n",
    "    test_no = test_no + 1\n",
    "    summary = []\n",
    "    summary.append(test_results)\n",
    "    return test_no, summary, hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exp:d</h2>\n",
    "<br>\n",
    "2layer 360 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_net4():\n",
    "    net1 = models.Sequential()\n",
    "    net1.add(layers.Dense(480, input_shape = (480,6)))\n",
    "    net1.add(layers.Dense (360, activation = 'softmax'))\n",
    "    net1.add(layers.Dense (360, activation = 'softmax'))\n",
    "    net1.add(layers.Flatten())\n",
    "    net1.add(layers.Dense(7, activation = 'sigmoid'))\n",
    "    net1.summary()\n",
    "    return net1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test4(net, test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels):\n",
    "    net.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    hist = net.fit(train_data, train_labels, epochs = 100, validation_data = (val_data, val_labels))\n",
    "    test_results = net.evaluate(test_data, test_labels)\n",
    "    test_results.insert(0,'360,360')\n",
    "    test_results.insert(1,test_no)\n",
    "    test_no = test_no + 1\n",
    "    summary = []\n",
    "    summary.append(test_results)\n",
    "    return test_no, summary, hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exp:e</h2><br>\n",
    "2layer 240 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_net5():\n",
    "    net1 = models.Sequential()\n",
    "    net1.add(layers.Dense(480, input_shape = (480,6)))\n",
    "    net1.add(layers.Dense (240, activation = 'softmax'))\n",
    "    net1.add(layers.Dense (240, activation = 'softmax'))\n",
    "    net1.add(layers.Flatten())\n",
    "    net1.add(layers.Dense(7, activation = 'sigmoid'))\n",
    "    net1.summary()\n",
    "    return net1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test5(net, test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels):\n",
    "    net.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    hist = net.fit(train_data, train_labels, epochs = 100, validation_data = (val_data, val_labels))\n",
    "    test_results = net.evaluate(test_data, test_labels)\n",
    "    test_results.insert(0,'240,240')\n",
    "    test_results.insert(1,test_no)\n",
    "    test_no = test_no + 1\n",
    "    summary = []\n",
    "    summary.append(test_results)\n",
    "    return test_no, summary, hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exp:f</h2>\n",
    "<br>\n",
    "2layer 120 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_net6():\n",
    "    net1 = models.Sequential()\n",
    "    net1.add(layers.Dense(480, input_shape = (480,6)))\n",
    "    net1.add(layers.Dense (120, activation = 'softmax'))\n",
    "    net1.add(layers.Dense (120, activation = 'softmax'))\n",
    "    net1.add(layers.Flatten())\n",
    "    net1.add(layers.Dense(7, activation = 'sigmoid'))\n",
    "    net1.summary()\n",
    "    return net1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test6(net, test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels):\n",
    "    net.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    hist = net.fit(train_data, train_labels, epochs = 100, validation_data = (val_data, val_labels))\n",
    "    test_results = net.evaluate(test_data, test_labels)\n",
    "    test_results.insert(0,'120,120')\n",
    "    test_results.insert(1,test_no)\n",
    "    test_no = test_no + 1\n",
    "    summary = []\n",
    "    summary.append(test_results)\n",
    "    return test_no, summary, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(data, labels):\n",
    "    start = time.time()\n",
    "    summary = []\n",
    "    histories = []\n",
    "    i = 1\n",
    "    test_no = 1\n",
    "    while i < 2:\n",
    "        train_data, train_labels, val_data, val_labels, test_data, test_labels = pp.cluster_shuffle(data, labels)\n",
    "        net1 = build_net1()\n",
    "        test_no, summary1, history1 = train_test1(net1, test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "        histories.append(history1)\n",
    "        net2 = build_net2()        \n",
    "        test_no, summary2, history2 = train_test2(net2, test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "        histories.append(history2)\n",
    "        net3 = build_net3()        \n",
    "        test_no, summary3, history3 = train_test3(net3, test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "        histories.append(history3)\n",
    "        net4 = build_net4()        \n",
    "        test_no, summary4, history4 = train_test4(net4, test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "        histories.append(history4)\n",
    "        net5 = build_net5()        \n",
    "        test_no, summary5, history5 = train_test5(net5, test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "        histories.append(history5)\n",
    "        net6 = build_net6()        \n",
    "        test_no, summary6, history6 = train_test6(net6, test_no, train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "        histories.append(history6)\n",
    "        summary = summary + summary1 + summary2 + summary3 + summary4 + summary5 + summary6\n",
    "        i = i + 1 \n",
    "    print(summary)\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print('Time elapsed: ', elapsed)\n",
    "    with open('ENB12_results.txt', 'wb') as fp:\n",
    "        pickle.dump(summary, fp)\n",
    "    with open('ENB12_histories.txt', 'wb') as fp:\n",
    "        pickle.dump(histories, fp)\n",
    "    return summary, histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHUFFLING ARRAYS\n",
      "act0 shape:  (7, 480, 6)\n",
      "act1 shape:  (5, 480, 6)\n",
      "act2 shape:  (15, 480, 6)\n",
      "act3 shape:  (15, 480, 6)\n",
      "act4 shape:  (15, 480, 6)\n",
      "act5 shape:  (15, 480, 6)\n",
      "act6 shape:  (15, 480, 6)\n",
      "SLICING ARRAYS\n",
      "(4, 480, 6)\n",
      "(2, 480, 6)\n",
      "(1, 480, 6)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 480, 480)          3360      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 480, 720)          346320    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 480, 720)          519120    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 345600)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 2419207   \n",
      "=================================================================\n",
      "Total params: 3,288,007\n",
      "Trainable params: 3,288,007\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\Ryan\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Ryan\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 1.9496 - accuracy: 0.0962 - val_loss: 1.9094 - val_accuracy: 0.1667\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.8959 - accuracy: 0.1538 - val_loss: 1.9093 - val_accuracy: 0.1667\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 1.8857 - accuracy: 0.1154 - val_loss: 1.9221 - val_accuracy: 0.1667\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8932 - accuracy: 0.1731 - val_loss: 1.9284 - val_accuracy: 0.1667\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 1.8962 - accuracy: 0.1731 - val_loss: 1.9218 - val_accuracy: 0.1667\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 1.8909 - accuracy: 0.1731 - val_loss: 1.9180 - val_accuracy: 0.1667\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 1s 29ms/step - loss: 1.8849 - accuracy: 0.1731 - val_loss: 1.9106 - val_accuracy: 0.1667\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 1s 29ms/step - loss: 1.8888 - accuracy: 0.1731 - val_loss: 1.9061 - val_accuracy: 0.1667\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.8887 - accuracy: 0.1731 - val_loss: 1.9054 - val_accuracy: 0.1667\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 1.8842 - accuracy: 0.1731 - val_loss: 1.9048 - val_accuracy: 0.1667\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 1s 29ms/step - loss: 1.8855 - accuracy: 0.1731 - val_loss: 1.9030 - val_accuracy: 0.1667\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8822 - accuracy: 0.1731 - val_loss: 1.9037 - val_accuracy: 0.1667\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9043 - val_accuracy: 0.1667\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 1.8819 - accuracy: 0.2308 - val_loss: 1.9046 - val_accuracy: 0.1667\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9066 - val_accuracy: 0.1667\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 1.8807 - accuracy: 0.1731 - val_loss: 1.9085 - val_accuracy: 0.1667\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8825 - accuracy: 0.1731 - val_loss: 1.9118 - val_accuracy: 0.1667\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 1.8827 - accuracy: 0.1731 - val_loss: 1.9123 - val_accuracy: 0.1667\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.8825 - accuracy: 0.1731 - val_loss: 1.9136 - val_accuracy: 0.1667\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 1.8844 - accuracy: 0.1731 - val_loss: 1.9133 - val_accuracy: 0.1667\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 1.8824 - accuracy: 0.1731 - val_loss: 1.9140 - val_accuracy: 0.1667\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.8828 - accuracy: 0.1731 - val_loss: 1.9122 - val_accuracy: 0.1667\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 1.8818 - accuracy: 0.1731 - val_loss: 1.9101 - val_accuracy: 0.1667\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 1.8816 - accuracy: 0.1731 - val_loss: 1.9083 - val_accuracy: 0.1667\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9070 - val_accuracy: 0.1667\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.8807 - accuracy: 0.1731 - val_loss: 1.9054 - val_accuracy: 0.1667\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 1.8821 - accuracy: 0.1731 - val_loss: 1.9038 - val_accuracy: 0.1667\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.8832 - accuracy: 0.1731 - val_loss: 1.9029 - val_accuracy: 0.1667\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 1.8825 - accuracy: 0.1731 - val_loss: 1.9040 - val_accuracy: 0.1667\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 1.8828 - accuracy: 0.1731 - val_loss: 1.9037 - val_accuracy: 0.1667\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9050 - val_accuracy: 0.1667\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 1s 29ms/step - loss: 1.8813 - accuracy: 0.1731 - val_loss: 1.9057 - val_accuracy: 0.1667\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.8816 - accuracy: 0.1731 - val_loss: 1.9060 - val_accuracy: 0.1667\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9059 - val_accuracy: 0.1667\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8811 - accuracy: 0.1731 - val_loss: 1.9044 - val_accuracy: 0.1667\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.8799 - accuracy: 0.1731 - val_loss: 1.9033 - val_accuracy: 0.1667\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 1.8817 - accuracy: 0.1731 - val_loss: 1.9017 - val_accuracy: 0.1667\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 1s 29ms/step - loss: 1.8817 - accuracy: 0.1538 - val_loss: 1.9015 - val_accuracy: 0.1667\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 1.8817 - accuracy: 0.1731 - val_loss: 1.9015 - val_accuracy: 0.1667\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8811 - accuracy: 0.1731 - val_loss: 1.9017 - val_accuracy: 0.1667\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.8829 - accuracy: 0.1731 - val_loss: 1.9026 - val_accuracy: 0.1667\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9045 - val_accuracy: 0.1667\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 1s 29ms/step - loss: 1.8814 - accuracy: 0.1731 - val_loss: 1.9071 - val_accuracy: 0.1667\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8813 - accuracy: 0.1731 - val_loss: 1.9095 - val_accuracy: 0.1667\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 1s 29ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9101 - val_accuracy: 0.1667\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 1.8814 - accuracy: 0.1731 - val_loss: 1.9102 - val_accuracy: 0.1667\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9103 - val_accuracy: 0.1667\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9089 - val_accuracy: 0.1667\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 1.8815 - accuracy: 0.1731 - val_loss: 1.9069 - val_accuracy: 0.1667\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 1s 29ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9040 - val_accuracy: 0.1667\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9020 - val_accuracy: 0.1667\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.8839 - accuracy: 0.1731 - val_loss: 1.9006 - val_accuracy: 0.1667\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8814 - accuracy: 0.1731 - val_loss: 1.9009 - val_accuracy: 0.1667\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9021 - val_accuracy: 0.1667\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 1.8817 - accuracy: 0.1731 - val_loss: 1.9043 - val_accuracy: 0.1667\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8816 - accuracy: 0.1731 - val_loss: 1.9061 - val_accuracy: 0.1667\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9084 - val_accuracy: 0.1667\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8802 - accuracy: 0.1346 - val_loss: 1.9091 - val_accuracy: 0.1667\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9096 - val_accuracy: 0.1667\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 1.8807 - accuracy: 0.1731 - val_loss: 1.9084 - val_accuracy: 0.1667\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 1.8839 - accuracy: 0.1731 - val_loss: 1.9071 - val_accuracy: 0.1667\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 1.8804 - accuracy: 0.1731 - val_loss: 1.9078 - val_accuracy: 0.1667\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8845 - accuracy: 0.1731 - val_loss: 1.9081 - val_accuracy: 0.1667\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8804 - accuracy: 0.1731 - val_loss: 1.9047 - val_accuracy: 0.1667\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.8817 - accuracy: 0.1731 - val_loss: 1.9023 - val_accuracy: 0.1667\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9013 - val_accuracy: 0.1667\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9008 - val_accuracy: 0.1667\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 1.8817 - accuracy: 0.1731 - val_loss: 1.9011 - val_accuracy: 0.1667\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 1.8814 - accuracy: 0.1731 - val_loss: 1.9029 - val_accuracy: 0.1667\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.8802 - accuracy: 0.1731 - val_loss: 1.9055 - val_accuracy: 0.1667\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 1.8849 - accuracy: 0.1731 - val_loss: 1.9091 - val_accuracy: 0.1667\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.8804 - accuracy: 0.1731 - val_loss: 1.9081 - val_accuracy: 0.1667\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 1s 29ms/step - loss: 1.8812 - accuracy: 0.1731 - val_loss: 1.9076 - val_accuracy: 0.1667\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8819 - accuracy: 0.1731 - val_loss: 1.9057 - val_accuracy: 0.1667\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8805 - accuracy: 0.1731 - val_loss: 1.9056 - val_accuracy: 0.1667\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 1s 29ms/step - loss: 1.8801 - accuracy: 0.1731 - val_loss: 1.9070 - val_accuracy: 0.1667\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 1.8816 - accuracy: 0.1923 - val_loss: 1.9088 - val_accuracy: 0.1667\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9099 - val_accuracy: 0.1667\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 1.8815 - accuracy: 0.1731 - val_loss: 1.9108 - val_accuracy: 0.1667\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 1.8823 - accuracy: 0.1538 - val_loss: 1.9099 - val_accuracy: 0.1667\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8811 - accuracy: 0.1731 - val_loss: 1.9079 - val_accuracy: 0.1667\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 1.8816 - accuracy: 0.1731 - val_loss: 1.9060 - val_accuracy: 0.1667\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 1.8797 - accuracy: 0.1731 - val_loss: 1.9026 - val_accuracy: 0.1667\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.8803 - accuracy: 0.1731 - val_loss: 1.9013 - val_accuracy: 0.1667\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 1.8843 - accuracy: 0.1731 - val_loss: 1.8999 - val_accuracy: 0.1667\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.8848 - accuracy: 0.1731 - val_loss: 1.8995 - val_accuracy: 0.1667\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.8841 - accuracy: 0.1731 - val_loss: 1.8997 - val_accuracy: 0.1667\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 1.8830 - accuracy: 0.1731 - val_loss: 1.9010 - val_accuracy: 0.1667\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9028 - val_accuracy: 0.1667\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 1.8800 - accuracy: 0.1731 - val_loss: 1.9059 - val_accuracy: 0.1667\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 1.8807 - accuracy: 0.1731 - val_loss: 1.9099 - val_accuracy: 0.1667\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8824 - accuracy: 0.1731 - val_loss: 1.9123 - val_accuracy: 0.1667\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8818 - accuracy: 0.1731 - val_loss: 1.9119 - val_accuracy: 0.1667\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 1.8824 - accuracy: 0.1731 - val_loss: 1.9089 - val_accuracy: 0.1667\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.8813 - accuracy: 0.1731 - val_loss: 1.9086 - val_accuracy: 0.1667\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 1.8821 - accuracy: 0.1731 - val_loss: 1.9062 - val_accuracy: 0.1667\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.8812 - accuracy: 0.1731 - val_loss: 1.9050 - val_accuracy: 0.1667\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 1.8823 - accuracy: 0.1731 - val_loss: 1.9026 - val_accuracy: 0.1667\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 1.8814 - accuracy: 0.1731 - val_loss: 1.9022 - val_accuracy: 0.1667\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 1s 29ms/step - loss: 1.8798 - accuracy: 0.1731 - val_loss: 1.9036 - val_accuracy: 0.1667\n",
      "17/17 [==============================] - 0s 7ms/step\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 480, 480)          3360      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 480, 600)          288600    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 480, 600)          360600    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 288000)            0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 2016007   \n",
      "=================================================================\n",
      "Total params: 2,668,567\n",
      "Trainable params: 2,668,567\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 1.9231 - accuracy: 0.1731 - val_loss: 1.9092 - val_accuracy: 0.1667\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8812 - accuracy: 0.1538 - val_loss: 1.9321 - val_accuracy: 0.1667\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.9000 - accuracy: 0.1538 - val_loss: 1.9474 - val_accuracy: 0.1667\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.9088 - accuracy: 0.1731 - val_loss: 1.9356 - val_accuracy: 0.1667\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8993 - accuracy: 0.1731 - val_loss: 1.9224 - val_accuracy: 0.1667\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8906 - accuracy: 0.1731 - val_loss: 1.9113 - val_accuracy: 0.1667\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8883 - accuracy: 0.1731 - val_loss: 1.9037 - val_accuracy: 0.1667\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8878 - accuracy: 0.1731 - val_loss: 1.9020 - val_accuracy: 0.1667\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8858 - accuracy: 0.1731 - val_loss: 1.9024 - val_accuracy: 0.1667\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 1.8840 - accuracy: 0.1731 - val_loss: 1.9018 - val_accuracy: 0.1667\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8817 - accuracy: 0.1731 - val_loss: 1.9026 - val_accuracy: 0.1667\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8834 - accuracy: 0.1731 - val_loss: 1.9049 - val_accuracy: 0.1667\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8816 - accuracy: 0.1731 - val_loss: 1.9068 - val_accuracy: 0.1667\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 1.8812 - accuracy: 0.1731 - val_loss: 1.9099 - val_accuracy: 0.1667\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 1.8821 - accuracy: 0.1538 - val_loss: 1.9141 - val_accuracy: 0.1667\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8824 - accuracy: 0.1731 - val_loss: 1.9152 - val_accuracy: 0.1667\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8838 - accuracy: 0.1731 - val_loss: 1.9166 - val_accuracy: 0.1667\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8842 - accuracy: 0.1731 - val_loss: 1.9144 - val_accuracy: 0.1667\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 1.8821 - accuracy: 0.1731 - val_loss: 1.9132 - val_accuracy: 0.1667\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 1.8829 - accuracy: 0.1731 - val_loss: 1.9116 - val_accuracy: 0.1667\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8820 - accuracy: 0.1731 - val_loss: 1.9100 - val_accuracy: 0.1667\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8834 - accuracy: 0.1731 - val_loss: 1.9088 - val_accuracy: 0.1667\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8843 - accuracy: 0.1731 - val_loss: 1.9060 - val_accuracy: 0.1667\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8817 - accuracy: 0.1731 - val_loss: 1.9044 - val_accuracy: 0.1667\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8802 - accuracy: 0.1731 - val_loss: 1.9027 - val_accuracy: 0.1667\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 1.8805 - accuracy: 0.1731 - val_loss: 1.9012 - val_accuracy: 0.1667\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8814 - accuracy: 0.1731 - val_loss: 1.9004 - val_accuracy: 0.1667\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 1.8817 - accuracy: 0.1731 - val_loss: 1.9005 - val_accuracy: 0.1667\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 1.8821 - accuracy: 0.1731 - val_loss: 1.9011 - val_accuracy: 0.1667\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 1.8818 - accuracy: 0.1731 - val_loss: 1.9017 - val_accuracy: 0.1667\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 1.8837 - accuracy: 0.1731 - val_loss: 1.9026 - val_accuracy: 0.1667\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8824 - accuracy: 0.1731 - val_loss: 1.9050 - val_accuracy: 0.1667\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8804 - accuracy: 0.1731 - val_loss: 1.9058 - val_accuracy: 0.1667\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 1.8813 - accuracy: 0.1731 - val_loss: 1.9065 - val_accuracy: 0.1667\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9088 - val_accuracy: 0.1667\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9098 - val_accuracy: 0.1667\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8811 - accuracy: 0.1731 - val_loss: 1.9091 - val_accuracy: 0.1667\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8821 - accuracy: 0.1731 - val_loss: 1.9088 - val_accuracy: 0.1667\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9066 - val_accuracy: 0.1667\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 1.8825 - accuracy: 0.1731 - val_loss: 1.9043 - val_accuracy: 0.1667\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8811 - accuracy: 0.1731 - val_loss: 1.9038 - val_accuracy: 0.1667\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 1.8815 - accuracy: 0.1731 - val_loss: 1.9043 - val_accuracy: 0.1667\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9039 - val_accuracy: 0.1667\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 1.8811 - accuracy: 0.1731 - val_loss: 1.9036 - val_accuracy: 0.1667\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8811 - accuracy: 0.1731 - val_loss: 1.9026 - val_accuracy: 0.1667\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8819 - accuracy: 0.1731 - val_loss: 1.9010 - val_accuracy: 0.1667\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9013 - val_accuracy: 0.1667\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8807 - accuracy: 0.1731 - val_loss: 1.9022 - val_accuracy: 0.1667\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 1.8823 - accuracy: 0.1731 - val_loss: 1.9047 - val_accuracy: 0.1667\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 1.8805 - accuracy: 0.1731 - val_loss: 1.9060 - val_accuracy: 0.1667\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 1.8817 - accuracy: 0.2115 - val_loss: 1.9062 - val_accuracy: 0.1667\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 1.8816 - accuracy: 0.1731 - val_loss: 1.9081 - val_accuracy: 0.1667\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8818 - accuracy: 0.1731 - val_loss: 1.9089 - val_accuracy: 0.1667\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9073 - val_accuracy: 0.1667\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 1.8825 - accuracy: 0.1731 - val_loss: 1.9068 - val_accuracy: 0.1667\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9064 - val_accuracy: 0.1667\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 1.8819 - accuracy: 0.1731 - val_loss: 1.9055 - val_accuracy: 0.1667\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 25ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9060 - val_accuracy: 0.1667\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9055 - val_accuracy: 0.1667\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 1.8811 - accuracy: 0.1731 - val_loss: 1.9061 - val_accuracy: 0.1667\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9049 - val_accuracy: 0.1667\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8799 - accuracy: 0.1731 - val_loss: 1.9046 - val_accuracy: 0.1667\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8800 - accuracy: 0.1731 - val_loss: 1.9043 - val_accuracy: 0.1667\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9041 - val_accuracy: 0.1667\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 1.8803 - accuracy: 0.1731 - val_loss: 1.9031 - val_accuracy: 0.1667\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9024 - val_accuracy: 0.1667\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8827 - accuracy: 0.1731 - val_loss: 1.9019 - val_accuracy: 0.1667\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9013 - val_accuracy: 0.1667\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 1.8811 - accuracy: 0.1731 - val_loss: 1.9013 - val_accuracy: 0.1667\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 1.8812 - accuracy: 0.1731 - val_loss: 1.9008 - val_accuracy: 0.1667\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 1.8819 - accuracy: 0.1731 - val_loss: 1.9011 - val_accuracy: 0.1667\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9026 - val_accuracy: 0.1667\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 1.8813 - accuracy: 0.1731 - val_loss: 1.9052 - val_accuracy: 0.1667\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 1.8814 - accuracy: 0.1731 - val_loss: 1.9080 - val_accuracy: 0.1667\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8800 - accuracy: 0.1731 - val_loss: 1.9092 - val_accuracy: 0.1667\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 1.8801 - accuracy: 0.1731 - val_loss: 1.9103 - val_accuracy: 0.1667\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8861 - accuracy: 0.1731 - val_loss: 1.9115 - val_accuracy: 0.1667\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 1.8820 - accuracy: 0.1731 - val_loss: 1.9092 - val_accuracy: 0.1667\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9063 - val_accuracy: 0.1667\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8805 - accuracy: 0.1923 - val_loss: 1.9048 - val_accuracy: 0.1667\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 1.8805 - accuracy: 0.1731 - val_loss: 1.9032 - val_accuracy: 0.1667\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8814 - accuracy: 0.1731 - val_loss: 1.9029 - val_accuracy: 0.1667\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8814 - accuracy: 0.1731 - val_loss: 1.9028 - val_accuracy: 0.1667\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8823 - accuracy: 0.1731 - val_loss: 1.9017 - val_accuracy: 0.1667\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 1.8826 - accuracy: 0.1731 - val_loss: 1.9026 - val_accuracy: 0.1667\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8812 - accuracy: 0.1731 - val_loss: 1.9019 - val_accuracy: 0.1667\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 1.8805 - accuracy: 0.1731 - val_loss: 1.9021 - val_accuracy: 0.1667\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8812 - accuracy: 0.1731 - val_loss: 1.9031 - val_accuracy: 0.1667\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 1.8804 - accuracy: 0.1731 - val_loss: 1.9038 - val_accuracy: 0.1667\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8803 - accuracy: 0.1731 - val_loss: 1.9049 - val_accuracy: 0.1667\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8800 - accuracy: 0.1731 - val_loss: 1.9074 - val_accuracy: 0.1667\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9102 - val_accuracy: 0.1667\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9112 - val_accuracy: 0.1667\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9102 - val_accuracy: 0.1667\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9092 - val_accuracy: 0.1667\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8811 - accuracy: 0.1731 - val_loss: 1.9072 - val_accuracy: 0.1667\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 1.8829 - accuracy: 0.1731 - val_loss: 1.9044 - val_accuracy: 0.1667\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8807 - accuracy: 0.1731 - val_loss: 1.9040 - val_accuracy: 0.1667\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9045 - val_accuracy: 0.1667\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8804 - accuracy: 0.1731 - val_loss: 1.9038 - val_accuracy: 0.1667\n",
      "17/17 [==============================] - 0s 5ms/step\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 480, 480)          3360      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 480, 480)          230880    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 480, 480)          230880    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 230400)            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 7)                 1612807   \n",
      "=================================================================\n",
      "Total params: 2,077,927\n",
      "Trainable params: 2,077,927\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 1.9681 - accuracy: 0.0962 - val_loss: 1.9155 - val_accuracy: 0.1667\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.9179 - accuracy: 0.1731 - val_loss: 1.9204 - val_accuracy: 0.1667\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 1.8924 - accuracy: 0.1731 - val_loss: 1.9227 - val_accuracy: 0.1667\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8918 - accuracy: 0.1731 - val_loss: 1.9207 - val_accuracy: 0.1667\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8969 - accuracy: 0.1731 - val_loss: 1.9164 - val_accuracy: 0.1667\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8909 - accuracy: 0.1731 - val_loss: 1.9094 - val_accuracy: 0.1667\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8853 - accuracy: 0.1731 - val_loss: 1.9059 - val_accuracy: 0.1667\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8814 - accuracy: 0.1731 - val_loss: 1.9046 - val_accuracy: 0.1667\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8849 - accuracy: 0.1731 - val_loss: 1.9054 - val_accuracy: 0.1667\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8825 - accuracy: 0.1731 - val_loss: 1.9056 - val_accuracy: 0.1667\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 1.8875 - accuracy: 0.1731 - val_loss: 1.9054 - val_accuracy: 0.1667\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8848 - accuracy: 0.1731 - val_loss: 1.9054 - val_accuracy: 0.1667\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8846 - accuracy: 0.1731 - val_loss: 1.9047 - val_accuracy: 0.1667\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8817 - accuracy: 0.1731 - val_loss: 1.9055 - val_accuracy: 0.1667\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8821 - accuracy: 0.1731 - val_loss: 1.9077 - val_accuracy: 0.1667\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8818 - accuracy: 0.1731 - val_loss: 1.9108 - val_accuracy: 0.1667\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8833 - accuracy: 0.1731 - val_loss: 1.9114 - val_accuracy: 0.1667\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8823 - accuracy: 0.1731 - val_loss: 1.9091 - val_accuracy: 0.1667\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8829 - accuracy: 0.1346 - val_loss: 1.9077 - val_accuracy: 0.1667\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 1.8818 - accuracy: 0.1731 - val_loss: 1.9055 - val_accuracy: 0.1667\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8829 - accuracy: 0.1731 - val_loss: 1.9047 - val_accuracy: 0.1667\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8821 - accuracy: 0.1731 - val_loss: 1.9049 - val_accuracy: 0.1667\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8834 - accuracy: 0.1731 - val_loss: 1.9065 - val_accuracy: 0.1667\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8820 - accuracy: 0.1731 - val_loss: 1.9055 - val_accuracy: 0.1667\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8838 - accuracy: 0.1731 - val_loss: 1.9051 - val_accuracy: 0.1667\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9069 - val_accuracy: 0.1667\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 1.8813 - accuracy: 0.1731 - val_loss: 1.9090 - val_accuracy: 0.1667\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8827 - accuracy: 0.0577 - val_loss: 1.9109 - val_accuracy: 0.1667\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 1.8822 - accuracy: 0.1731 - val_loss: 1.9123 - val_accuracy: 0.1667\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8841 - accuracy: 0.1731 - val_loss: 1.9101 - val_accuracy: 0.1667\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8808 - accuracy: 0.1923 - val_loss: 1.9098 - val_accuracy: 0.1667\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9092 - val_accuracy: 0.1667\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8812 - accuracy: 0.1731 - val_loss: 1.9085 - val_accuracy: 0.1667\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8825 - accuracy: 0.1731 - val_loss: 1.9085 - val_accuracy: 0.1667\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8812 - accuracy: 0.1731 - val_loss: 1.9056 - val_accuracy: 0.1667\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8835 - accuracy: 0.1731 - val_loss: 1.9040 - val_accuracy: 0.1667\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9043 - val_accuracy: 0.1667\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8819 - accuracy: 0.1731 - val_loss: 1.9057 - val_accuracy: 0.1667\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8811 - accuracy: 0.1731 - val_loss: 1.9059 - val_accuracy: 0.1667\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8806 - accuracy: 0.1538 - val_loss: 1.9080 - val_accuracy: 0.1667\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8803 - accuracy: 0.1731 - val_loss: 1.9100 - val_accuracy: 0.1667\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8824 - accuracy: 0.1923 - val_loss: 1.9121 - val_accuracy: 0.1667\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8812 - accuracy: 0.1731 - val_loss: 1.9100 - val_accuracy: 0.1667\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8811 - accuracy: 0.1731 - val_loss: 1.9070 - val_accuracy: 0.1667\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8824 - accuracy: 0.1731 - val_loss: 1.9041 - val_accuracy: 0.1667\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8838 - accuracy: 0.1731 - val_loss: 1.9024 - val_accuracy: 0.1667\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8823 - accuracy: 0.1731 - val_loss: 1.9029 - val_accuracy: 0.1667\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8814 - accuracy: 0.1731 - val_loss: 1.9043 - val_accuracy: 0.1667\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8825 - accuracy: 0.1731 - val_loss: 1.9069 - val_accuracy: 0.1667\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8803 - accuracy: 0.1731 - val_loss: 1.9072 - val_accuracy: 0.1667\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8813 - accuracy: 0.1731 - val_loss: 1.9069 - val_accuracy: 0.1667\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8799 - accuracy: 0.1731 - val_loss: 1.9047 - val_accuracy: 0.1667\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9030 - val_accuracy: 0.1667\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8826 - accuracy: 0.1731 - val_loss: 1.9017 - val_accuracy: 0.1667\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 1.8819 - accuracy: 0.1731 - val_loss: 1.9018 - val_accuracy: 0.1667\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8812 - accuracy: 0.1731 - val_loss: 1.9029 - val_accuracy: 0.1667\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 1.8823 - accuracy: 0.1731 - val_loss: 1.9051 - val_accuracy: 0.1667\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8816 - accuracy: 0.1731 - val_loss: 1.9077 - val_accuracy: 0.1667\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8832 - accuracy: 0.1154 - val_loss: 1.9102 - val_accuracy: 0.1667\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9125 - val_accuracy: 0.1667\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 1.8841 - accuracy: 0.1731 - val_loss: 1.9139 - val_accuracy: 0.1667\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8819 - accuracy: 0.1731 - val_loss: 1.9116 - val_accuracy: 0.1667\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8820 - accuracy: 0.1731 - val_loss: 1.9095 - val_accuracy: 0.1667\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8817 - accuracy: 0.1731 - val_loss: 1.9061 - val_accuracy: 0.1667\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8822 - accuracy: 0.1731 - val_loss: 1.9041 - val_accuracy: 0.1667\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8805 - accuracy: 0.1731 - val_loss: 1.9045 - val_accuracy: 0.1667\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9044 - val_accuracy: 0.1667\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8802 - accuracy: 0.1731 - val_loss: 1.9052 - val_accuracy: 0.1667\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9055 - val_accuracy: 0.1667\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8819 - accuracy: 0.1731 - val_loss: 1.9050 - val_accuracy: 0.1667\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8811 - accuracy: 0.1731 - val_loss: 1.9064 - val_accuracy: 0.1667\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9075 - val_accuracy: 0.1667\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8811 - accuracy: 0.1731 - val_loss: 1.9105 - val_accuracy: 0.1667\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8812 - accuracy: 0.1731 - val_loss: 1.9114 - val_accuracy: 0.1667\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8811 - accuracy: 0.1731 - val_loss: 1.9101 - val_accuracy: 0.1667\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9076 - val_accuracy: 0.1667\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8837 - accuracy: 0.1731 - val_loss: 1.9034 - val_accuracy: 0.1667\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8817 - accuracy: 0.1731 - val_loss: 1.9027 - val_accuracy: 0.1667\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8816 - accuracy: 0.1731 - val_loss: 1.9011 - val_accuracy: 0.1667\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8823 - accuracy: 0.1731 - val_loss: 1.9009 - val_accuracy: 0.1667\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8823 - accuracy: 0.1731 - val_loss: 1.9021 - val_accuracy: 0.1667\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8803 - accuracy: 0.1731 - val_loss: 1.9055 - val_accuracy: 0.1667\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8807 - accuracy: 0.1731 - val_loss: 1.9108 - val_accuracy: 0.1667\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8811 - accuracy: 0.1731 - val_loss: 1.9158 - val_accuracy: 0.1667\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8842 - accuracy: 0.1731 - val_loss: 1.9218 - val_accuracy: 0.1667\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8861 - accuracy: 0.1731 - val_loss: 1.9212 - val_accuracy: 0.1667\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8859 - accuracy: 0.1731 - val_loss: 1.9160 - val_accuracy: 0.1667\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8817 - accuracy: 0.1731 - val_loss: 1.9075 - val_accuracy: 0.1667\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8795 - accuracy: 0.1731 - val_loss: 1.9023 - val_accuracy: 0.1667\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8839 - accuracy: 0.1731 - val_loss: 1.9004 - val_accuracy: 0.1667\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 1.8829 - accuracy: 0.1731 - val_loss: 1.8991 - val_accuracy: 0.1667\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8841 - accuracy: 0.1731 - val_loss: 1.8988 - val_accuracy: 0.1667\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8835 - accuracy: 0.1731 - val_loss: 1.8987 - val_accuracy: 0.1667\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8845 - accuracy: 0.1731 - val_loss: 1.8993 - val_accuracy: 0.1667\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8817 - accuracy: 0.1731 - val_loss: 1.9009 - val_accuracy: 0.1667\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 1.8818 - accuracy: 0.1731 - val_loss: 1.9037 - val_accuracy: 0.1667\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 1.8811 - accuracy: 0.1731 - val_loss: 1.9062 - val_accuracy: 0.1667\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8812 - accuracy: 0.1731 - val_loss: 1.9085 - val_accuracy: 0.1667\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8840 - accuracy: 0.1731 - val_loss: 1.9107 - val_accuracy: 0.1667\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8821 - accuracy: 0.1731 - val_loss: 1.9093 - val_accuracy: 0.1667\n",
      "17/17 [==============================] - 0s 4ms/step\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 480, 480)          3360      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 480, 360)          173160    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 480, 360)          129960    \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 172800)            0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 7)                 1209607   \n",
      "=================================================================\n",
      "Total params: 1,516,087\n",
      "Trainable params: 1,516,087\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 1.9390 - accuracy: 0.1538 - val_loss: 1.9025 - val_accuracy: 0.1667\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8911 - accuracy: 0.1154 - val_loss: 1.9121 - val_accuracy: 0.1667\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8969 - accuracy: 0.1731 - val_loss: 1.9222 - val_accuracy: 0.1667\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8941 - accuracy: 0.1538 - val_loss: 1.9153 - val_accuracy: 0.1667\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8914 - accuracy: 0.1731 - val_loss: 1.9129 - val_accuracy: 0.1667\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8845 - accuracy: 0.1731 - val_loss: 1.9085 - val_accuracy: 0.1667\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8822 - accuracy: 0.1731 - val_loss: 1.9066 - val_accuracy: 0.1667\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8847 - accuracy: 0.1731 - val_loss: 1.9085 - val_accuracy: 0.1667\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8846 - accuracy: 0.1731 - val_loss: 1.9090 - val_accuracy: 0.1667\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8850 - accuracy: 0.1731 - val_loss: 1.9070 - val_accuracy: 0.1667\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8826 - accuracy: 0.1731 - val_loss: 1.9064 - val_accuracy: 0.1667\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8827 - accuracy: 0.1731 - val_loss: 1.9053 - val_accuracy: 0.1667\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8804 - accuracy: 0.1731 - val_loss: 1.9054 - val_accuracy: 0.1667\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8826 - accuracy: 0.1731 - val_loss: 1.9066 - val_accuracy: 0.1667\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8851 - accuracy: 0.1731 - val_loss: 1.9085 - val_accuracy: 0.1667\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8824 - accuracy: 0.1731 - val_loss: 1.9080 - val_accuracy: 0.1667\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.8816 - accuracy: 0.1154 - val_loss: 1.9094 - val_accuracy: 0.1667\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8826 - accuracy: 0.1731 - val_loss: 1.9096 - val_accuracy: 0.1667\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.8824 - accuracy: 0.1731 - val_loss: 1.9088 - val_accuracy: 0.1667\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8817 - accuracy: 0.1731 - val_loss: 1.9058 - val_accuracy: 0.1667\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8801 - accuracy: 0.1731 - val_loss: 1.9042 - val_accuracy: 0.1667\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8836 - accuracy: 0.1731 - val_loss: 1.9029 - val_accuracy: 0.1667\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8815 - accuracy: 0.1731 - val_loss: 1.9034 - val_accuracy: 0.1667\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8812 - accuracy: 0.1731 - val_loss: 1.9038 - val_accuracy: 0.1667\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8812 - accuracy: 0.0769 - val_loss: 1.9051 - val_accuracy: 0.1667\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.8816 - accuracy: 0.1731 - val_loss: 1.9066 - val_accuracy: 0.1667\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9085 - val_accuracy: 0.1667\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8837 - accuracy: 0.1731 - val_loss: 1.9106 - val_accuracy: 0.1667\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.8828 - accuracy: 0.1731 - val_loss: 1.9091 - val_accuracy: 0.1667\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8831 - accuracy: 0.1731 - val_loss: 1.9095 - val_accuracy: 0.1667\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8820 - accuracy: 0.1731 - val_loss: 1.9079 - val_accuracy: 0.1667\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9050 - val_accuracy: 0.1667\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8816 - accuracy: 0.1731 - val_loss: 1.9031 - val_accuracy: 0.1667\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8821 - accuracy: 0.1731 - val_loss: 1.9021 - val_accuracy: 0.1667\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8842 - accuracy: 0.1731 - val_loss: 1.9017 - val_accuracy: 0.1667\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8830 - accuracy: 0.1731 - val_loss: 1.9012 - val_accuracy: 0.1667\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.8829 - accuracy: 0.1731 - val_loss: 1.9016 - val_accuracy: 0.1667\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9019 - val_accuracy: 0.1667\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8813 - accuracy: 0.1731 - val_loss: 1.9026 - val_accuracy: 0.1667\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8801 - accuracy: 0.1731 - val_loss: 1.9027 - val_accuracy: 0.1667\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8805 - accuracy: 0.1731 - val_loss: 1.9035 - val_accuracy: 0.1667\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8811 - accuracy: 0.1731 - val_loss: 1.9051 - val_accuracy: 0.1667\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9063 - val_accuracy: 0.1667\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8817 - accuracy: 0.1731 - val_loss: 1.9068 - val_accuracy: 0.1667\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8818 - accuracy: 0.1731 - val_loss: 1.9065 - val_accuracy: 0.1667\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8815 - accuracy: 0.1731 - val_loss: 1.9057 - val_accuracy: 0.1667\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.8807 - accuracy: 0.1731 - val_loss: 1.9058 - val_accuracy: 0.1667\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8813 - accuracy: 0.1731 - val_loss: 1.9056 - val_accuracy: 0.1667\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8827 - accuracy: 0.1731 - val_loss: 1.9038 - val_accuracy: 0.1667\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8816 - accuracy: 0.1731 - val_loss: 1.9040 - val_accuracy: 0.1667\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8805 - accuracy: 0.1731 - val_loss: 1.9040 - val_accuracy: 0.1667\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9048 - val_accuracy: 0.1667\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.8805 - accuracy: 0.1731 - val_loss: 1.9052 - val_accuracy: 0.1667\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8801 - accuracy: 0.1731 - val_loss: 1.9051 - val_accuracy: 0.1667\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8803 - accuracy: 0.1731 - val_loss: 1.9059 - val_accuracy: 0.1667\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.8827 - accuracy: 0.1731 - val_loss: 1.9074 - val_accuracy: 0.1667\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9060 - val_accuracy: 0.1667\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8816 - accuracy: 0.1731 - val_loss: 1.9050 - val_accuracy: 0.1667\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8805 - accuracy: 0.1731 - val_loss: 1.9055 - val_accuracy: 0.1667\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8840 - accuracy: 0.1731 - val_loss: 1.9079 - val_accuracy: 0.1667\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8816 - accuracy: 0.1731 - val_loss: 1.9070 - val_accuracy: 0.1667\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8800 - accuracy: 0.1731 - val_loss: 1.9047 - val_accuracy: 0.1667\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9028 - val_accuracy: 0.1667\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9023 - val_accuracy: 0.1667\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9020 - val_accuracy: 0.1667\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8824 - accuracy: 0.1731 - val_loss: 1.9018 - val_accuracy: 0.1667\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8818 - accuracy: 0.1731 - val_loss: 1.9030 - val_accuracy: 0.1667\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.8801 - accuracy: 0.1731 - val_loss: 1.9041 - val_accuracy: 0.1667\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8799 - accuracy: 0.1731 - val_loss: 1.9059 - val_accuracy: 0.1667\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9081 - val_accuracy: 0.1667\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9099 - val_accuracy: 0.1667\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8811 - accuracy: 0.1154 - val_loss: 1.9114 - val_accuracy: 0.1667\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8827 - accuracy: 0.1154 - val_loss: 1.9127 - val_accuracy: 0.1667\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.8819 - accuracy: 0.1731 - val_loss: 1.9098 - val_accuracy: 0.1667\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.8823 - accuracy: 0.1731 - val_loss: 1.9072 - val_accuracy: 0.1667\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8805 - accuracy: 0.1731 - val_loss: 1.9064 - val_accuracy: 0.1667\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9058 - val_accuracy: 0.1667\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9065 - val_accuracy: 0.1667\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9087 - val_accuracy: 0.1667\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.8803 - accuracy: 0.1731 - val_loss: 1.9096 - val_accuracy: 0.1667\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9104 - val_accuracy: 0.1667\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8823 - accuracy: 0.1731 - val_loss: 1.9106 - val_accuracy: 0.1667\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.8816 - accuracy: 0.1731 - val_loss: 1.9100 - val_accuracy: 0.1667\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8819 - accuracy: 0.1731 - val_loss: 1.9090 - val_accuracy: 0.1667\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8803 - accuracy: 0.1731 - val_loss: 1.9097 - val_accuracy: 0.1667\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8822 - accuracy: 0.1154 - val_loss: 1.9103 - val_accuracy: 0.1667\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.8819 - accuracy: 0.1538 - val_loss: 1.9106 - val_accuracy: 0.1667\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.8821 - accuracy: 0.1731 - val_loss: 1.9080 - val_accuracy: 0.1667\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9059 - val_accuracy: 0.1667\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8798 - accuracy: 0.1731 - val_loss: 1.9041 - val_accuracy: 0.1667\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8805 - accuracy: 0.1731 - val_loss: 1.9025 - val_accuracy: 0.1667\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8803 - accuracy: 0.1731 - val_loss: 1.9021 - val_accuracy: 0.1667\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8804 - accuracy: 0.1731 - val_loss: 1.9019 - val_accuracy: 0.1667\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8803 - accuracy: 0.1731 - val_loss: 1.9025 - val_accuracy: 0.1667\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8805 - accuracy: 0.1731 - val_loss: 1.9039 - val_accuracy: 0.1667\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8813 - accuracy: 0.1731 - val_loss: 1.9051 - val_accuracy: 0.1667\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9048 - val_accuracy: 0.1667\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8801 - accuracy: 0.1731 - val_loss: 1.9049 - val_accuracy: 0.1667\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.8796 - accuracy: 0.1731 - val_loss: 1.9058 - val_accuracy: 0.1667\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8804 - accuracy: 0.1731 - val_loss: 1.9075 - val_accuracy: 0.1667\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 480, 480)          3360      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 480, 240)          115440    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 480, 240)          57840     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 115200)            0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 7)                 806407    \n",
      "=================================================================\n",
      "Total params: 983,047\n",
      "Trainable params: 983,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.9508 - accuracy: 0.0962 - val_loss: 1.9169 - val_accuracy: 0.1667\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8882 - accuracy: 0.0962 - val_loss: 1.9309 - val_accuracy: 0.1667\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8915 - accuracy: 0.1731 - val_loss: 1.9406 - val_accuracy: 0.1667\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.9046 - accuracy: 0.1731 - val_loss: 1.9390 - val_accuracy: 0.1667\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8994 - accuracy: 0.1538 - val_loss: 1.9215 - val_accuracy: 0.1667\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8936 - accuracy: 0.1731 - val_loss: 1.9070 - val_accuracy: 0.1667\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8907 - accuracy: 0.1731 - val_loss: 1.9021 - val_accuracy: 0.1667\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8901 - accuracy: 0.1731 - val_loss: 1.9016 - val_accuracy: 0.1667\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8904 - accuracy: 0.1731 - val_loss: 1.9013 - val_accuracy: 0.1667\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8886 - accuracy: 0.1731 - val_loss: 1.9011 - val_accuracy: 0.1667\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8856 - accuracy: 0.1731 - val_loss: 1.9013 - val_accuracy: 0.1667\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8847 - accuracy: 0.1731 - val_loss: 1.9024 - val_accuracy: 0.1667\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8814 - accuracy: 0.1731 - val_loss: 1.9031 - val_accuracy: 0.1667\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8816 - accuracy: 0.1731 - val_loss: 1.9046 - val_accuracy: 0.1667\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8813 - accuracy: 0.1731 - val_loss: 1.9048 - val_accuracy: 0.1667\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8813 - accuracy: 0.1731 - val_loss: 1.9046 - val_accuracy: 0.1667\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8841 - accuracy: 0.1731 - val_loss: 1.9057 - val_accuracy: 0.1667\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8818 - accuracy: 0.1731 - val_loss: 1.9044 - val_accuracy: 0.1667\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8837 - accuracy: 0.1731 - val_loss: 1.9040 - val_accuracy: 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8846 - accuracy: 0.1731 - val_loss: 1.9059 - val_accuracy: 0.1667\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9050 - val_accuracy: 0.1667\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9038 - val_accuracy: 0.1667\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8818 - accuracy: 0.1731 - val_loss: 1.9037 - val_accuracy: 0.1667\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8802 - accuracy: 0.1731 - val_loss: 1.9037 - val_accuracy: 0.1667\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9035 - val_accuracy: 0.1667\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8814 - accuracy: 0.1731 - val_loss: 1.9044 - val_accuracy: 0.1667\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9050 - val_accuracy: 0.1667\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8824 - accuracy: 0.1731 - val_loss: 1.9048 - val_accuracy: 0.1667\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8812 - accuracy: 0.1731 - val_loss: 1.9059 - val_accuracy: 0.1667\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8821 - accuracy: 0.1731 - val_loss: 1.9074 - val_accuracy: 0.1667\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9103 - val_accuracy: 0.1667\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8839 - accuracy: 0.1731 - val_loss: 1.9134 - val_accuracy: 0.1667\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8819 - accuracy: 0.1731 - val_loss: 1.9115 - val_accuracy: 0.1667\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8817 - accuracy: 0.1731 - val_loss: 1.9094 - val_accuracy: 0.1667\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9078 - val_accuracy: 0.1667\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8852 - accuracy: 0.1154 - val_loss: 1.9055 - val_accuracy: 0.1667\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8818 - accuracy: 0.1731 - val_loss: 1.9049 - val_accuracy: 0.1667\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8819 - accuracy: 0.1731 - val_loss: 1.9034 - val_accuracy: 0.1667\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9018 - val_accuracy: 0.1667\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8835 - accuracy: 0.1731 - val_loss: 1.9021 - val_accuracy: 0.1667\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8831 - accuracy: 0.1731 - val_loss: 1.9025 - val_accuracy: 0.1667\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8823 - accuracy: 0.2115 - val_loss: 1.9025 - val_accuracy: 0.1667\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8825 - accuracy: 0.1731 - val_loss: 1.9025 - val_accuracy: 0.1667\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8848 - accuracy: 0.1731 - val_loss: 1.9025 - val_accuracy: 0.1667\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8817 - accuracy: 0.1731 - val_loss: 1.9028 - val_accuracy: 0.1667\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8823 - accuracy: 0.1731 - val_loss: 1.9051 - val_accuracy: 0.1667\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8804 - accuracy: 0.1731 - val_loss: 1.9059 - val_accuracy: 0.1667\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8821 - accuracy: 0.1731 - val_loss: 1.9067 - val_accuracy: 0.1667\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8805 - accuracy: 0.1731 - val_loss: 1.9081 - val_accuracy: 0.1667\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8824 - accuracy: 0.1731 - val_loss: 1.9097 - val_accuracy: 0.1667\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8835 - accuracy: 0.1731 - val_loss: 1.9104 - val_accuracy: 0.1667\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9082 - val_accuracy: 0.1667\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8802 - accuracy: 0.1731 - val_loss: 1.9055 - val_accuracy: 0.1667\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8816 - accuracy: 0.1731 - val_loss: 1.9032 - val_accuracy: 0.1667\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8802 - accuracy: 0.1731 - val_loss: 1.9025 - val_accuracy: 0.1667\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9020 - val_accuracy: 0.1667\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9019 - val_accuracy: 0.1667\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8807 - accuracy: 0.1731 - val_loss: 1.9022 - val_accuracy: 0.1667\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8804 - accuracy: 0.1731 - val_loss: 1.9026 - val_accuracy: 0.1667\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8828 - accuracy: 0.1346 - val_loss: 1.9034 - val_accuracy: 0.1667\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9037 - val_accuracy: 0.1667\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8812 - accuracy: 0.1731 - val_loss: 1.9037 - val_accuracy: 0.1667\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8818 - accuracy: 0.1731 - val_loss: 1.9036 - val_accuracy: 0.1667\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9052 - val_accuracy: 0.1667\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9063 - val_accuracy: 0.1667\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8813 - accuracy: 0.1731 - val_loss: 1.9069 - val_accuracy: 0.1667\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8812 - accuracy: 0.1731 - val_loss: 1.9052 - val_accuracy: 0.1667\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8815 - accuracy: 0.1731 - val_loss: 1.9043 - val_accuracy: 0.1667\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8820 - accuracy: 0.1731 - val_loss: 1.9051 - val_accuracy: 0.1667\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8849 - accuracy: 0.1923 - val_loss: 1.9076 - val_accuracy: 0.1667\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8814 - accuracy: 0.1731 - val_loss: 1.9063 - val_accuracy: 0.1667\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8822 - accuracy: 0.1731 - val_loss: 1.9059 - val_accuracy: 0.1667\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8819 - accuracy: 0.1731 - val_loss: 1.9058 - val_accuracy: 0.1667\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8804 - accuracy: 0.1731 - val_loss: 1.9061 - val_accuracy: 0.1667\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8830 - accuracy: 0.1731 - val_loss: 1.9057 - val_accuracy: 0.1667\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8801 - accuracy: 0.1731 - val_loss: 1.9058 - val_accuracy: 0.1667\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8816 - accuracy: 0.1731 - val_loss: 1.9065 - val_accuracy: 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8809 - accuracy: 0.1538 - val_loss: 1.9069 - val_accuracy: 0.1667\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8824 - accuracy: 0.1731 - val_loss: 1.9065 - val_accuracy: 0.1667\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9061 - val_accuracy: 0.1667\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8808 - accuracy: 0.1154 - val_loss: 1.9049 - val_accuracy: 0.1667\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8801 - accuracy: 0.1731 - val_loss: 1.9048 - val_accuracy: 0.1667\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9041 - val_accuracy: 0.1667\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8812 - accuracy: 0.1731 - val_loss: 1.9051 - val_accuracy: 0.1667\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8803 - accuracy: 0.1731 - val_loss: 1.9074 - val_accuracy: 0.1667\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8815 - accuracy: 0.1731 - val_loss: 1.9110 - val_accuracy: 0.1667\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8813 - accuracy: 0.1731 - val_loss: 1.9141 - val_accuracy: 0.1667\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8820 - accuracy: 0.1731 - val_loss: 1.9140 - val_accuracy: 0.1667\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8841 - accuracy: 0.1538 - val_loss: 1.9106 - val_accuracy: 0.1667\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8819 - accuracy: 0.1731 - val_loss: 1.9088 - val_accuracy: 0.1667\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8804 - accuracy: 0.1731 - val_loss: 1.9087 - val_accuracy: 0.1667\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8814 - accuracy: 0.1731 - val_loss: 1.9090 - val_accuracy: 0.1667\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9068 - val_accuracy: 0.1667\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8815 - accuracy: 0.1731 - val_loss: 1.9047 - val_accuracy: 0.1667\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9022 - val_accuracy: 0.1667\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.8812 - accuracy: 0.1731 - val_loss: 1.9013 - val_accuracy: 0.1667\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8812 - accuracy: 0.1731 - val_loss: 1.9008 - val_accuracy: 0.1667\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8818 - accuracy: 0.1731 - val_loss: 1.9011 - val_accuracy: 0.1667\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8807 - accuracy: 0.1731 - val_loss: 1.9028 - val_accuracy: 0.1667\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.8812 - accuracy: 0.1731 - val_loss: 1.9055 - val_accuracy: 0.1667\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 480, 480)          3360      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 480, 120)          57720     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 480, 120)          14520     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 7)                 403207    \n",
      "=================================================================\n",
      "Total params: 478,807\n",
      "Trainable params: 478,807\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 52 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.9519 - accuracy: 0.0962 - val_loss: 1.9151 - val_accuracy: 0.1667\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8979 - accuracy: 0.1538 - val_loss: 1.9185 - val_accuracy: 0.1667\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.9020 - accuracy: 0.0962 - val_loss: 1.9318 - val_accuracy: 0.1667\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8944 - accuracy: 0.1731 - val_loss: 1.9249 - val_accuracy: 0.1667\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8890 - accuracy: 0.1731 - val_loss: 1.9164 - val_accuracy: 0.1667\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8844 - accuracy: 0.1731 - val_loss: 1.9092 - val_accuracy: 0.1667\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8878 - accuracy: 0.1731 - val_loss: 1.9050 - val_accuracy: 0.1667\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8831 - accuracy: 0.1731 - val_loss: 1.9032 - val_accuracy: 0.1667\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8840 - accuracy: 0.1731 - val_loss: 1.9018 - val_accuracy: 0.1667\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8835 - accuracy: 0.1731 - val_loss: 1.9017 - val_accuracy: 0.1667\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8837 - accuracy: 0.1731 - val_loss: 1.9024 - val_accuracy: 0.1667\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8821 - accuracy: 0.1731 - val_loss: 1.9026 - val_accuracy: 0.1667\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8826 - accuracy: 0.1731 - val_loss: 1.9019 - val_accuracy: 0.1667\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9032 - val_accuracy: 0.1667\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8826 - accuracy: 0.1731 - val_loss: 1.9048 - val_accuracy: 0.1667\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8816 - accuracy: 0.1346 - val_loss: 1.9056 - val_accuracy: 0.1667\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8812 - accuracy: 0.1346 - val_loss: 1.9054 - val_accuracy: 0.1667\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9073 - val_accuracy: 0.1667\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9096 - val_accuracy: 0.1667\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9104 - val_accuracy: 0.1667\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8848 - accuracy: 0.1731 - val_loss: 1.9102 - val_accuracy: 0.1667\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8835 - accuracy: 0.1731 - val_loss: 1.9062 - val_accuracy: 0.1667\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9042 - val_accuracy: 0.1667\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8814 - accuracy: 0.1731 - val_loss: 1.9023 - val_accuracy: 0.1667\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8821 - accuracy: 0.1731 - val_loss: 1.9013 - val_accuracy: 0.1667\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8822 - accuracy: 0.1731 - val_loss: 1.9025 - val_accuracy: 0.1667\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8820 - accuracy: 0.1731 - val_loss: 1.9036 - val_accuracy: 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8808 - accuracy: 0.1731 - val_loss: 1.9043 - val_accuracy: 0.1667\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8807 - accuracy: 0.1731 - val_loss: 1.9047 - val_accuracy: 0.1667\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8804 - accuracy: 0.1731 - val_loss: 1.9072 - val_accuracy: 0.1667\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8820 - accuracy: 0.1923 - val_loss: 1.9084 - val_accuracy: 0.1667\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8867 - accuracy: 0.1731 - val_loss: 1.9113 - val_accuracy: 0.1667\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8831 - accuracy: 0.1731 - val_loss: 1.9082 - val_accuracy: 0.1667\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8819 - accuracy: 0.1731 - val_loss: 1.9072 - val_accuracy: 0.1667\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8811 - accuracy: 0.1731 - val_loss: 1.9069 - val_accuracy: 0.1667\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8805 - accuracy: 0.1731 - val_loss: 1.9060 - val_accuracy: 0.1667\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8817 - accuracy: 0.1731 - val_loss: 1.9056 - val_accuracy: 0.1667\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8802 - accuracy: 0.1731 - val_loss: 1.9056 - val_accuracy: 0.1667\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8832 - accuracy: 0.1731 - val_loss: 1.9062 - val_accuracy: 0.1667\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8805 - accuracy: 0.1731 - val_loss: 1.9070 - val_accuracy: 0.1667\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8818 - accuracy: 0.1731 - val_loss: 1.9085 - val_accuracy: 0.1667\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8814 - accuracy: 0.1731 - val_loss: 1.9081 - val_accuracy: 0.1667\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8829 - accuracy: 0.1923 - val_loss: 1.9055 - val_accuracy: 0.1667\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8815 - accuracy: 0.1731 - val_loss: 1.9049 - val_accuracy: 0.1667\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8823 - accuracy: 0.1731 - val_loss: 1.9029 - val_accuracy: 0.1667\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8822 - accuracy: 0.1731 - val_loss: 1.9024 - val_accuracy: 0.1667\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8800 - accuracy: 0.1731 - val_loss: 1.9037 - val_accuracy: 0.1667\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8802 - accuracy: 0.1731 - val_loss: 1.9058 - val_accuracy: 0.1667\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8827 - accuracy: 0.1731 - val_loss: 1.9074 - val_accuracy: 0.1667\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8805 - accuracy: 0.1731 - val_loss: 1.9067 - val_accuracy: 0.1667\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8804 - accuracy: 0.1731 - val_loss: 1.9065 - val_accuracy: 0.1667\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8800 - accuracy: 0.1731 - val_loss: 1.9058 - val_accuracy: 0.1667\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8814 - accuracy: 0.1731 - val_loss: 1.9044 - val_accuracy: 0.1667\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8801 - accuracy: 0.1731 - val_loss: 1.9047 - val_accuracy: 0.1667\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8826 - accuracy: 0.1731 - val_loss: 1.9055 - val_accuracy: 0.1667\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8813 - accuracy: 0.1731 - val_loss: 1.9069 - val_accuracy: 0.1667\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8818 - accuracy: 0.1731 - val_loss: 1.9075 - val_accuracy: 0.1667\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8813 - accuracy: 0.1731 - val_loss: 1.9076 - val_accuracy: 0.1667\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8815 - accuracy: 0.1731 - val_loss: 1.9082 - val_accuracy: 0.1667\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8804 - accuracy: 0.1154 - val_loss: 1.9072 - val_accuracy: 0.1667\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8800 - accuracy: 0.1731 - val_loss: 1.9069 - val_accuracy: 0.1667\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8804 - accuracy: 0.1731 - val_loss: 1.9061 - val_accuracy: 0.1667\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8804 - accuracy: 0.1731 - val_loss: 1.9050 - val_accuracy: 0.1667\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8818 - accuracy: 0.1154 - val_loss: 1.9047 - val_accuracy: 0.1667\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8831 - accuracy: 0.0962 - val_loss: 1.9062 - val_accuracy: 0.1667\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8827 - accuracy: 0.1731 - val_loss: 1.9078 - val_accuracy: 0.1667\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8831 - accuracy: 0.1538 - val_loss: 1.9103 - val_accuracy: 0.1667\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8823 - accuracy: 0.1731 - val_loss: 1.9097 - val_accuracy: 0.1667\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8807 - accuracy: 0.1731 - val_loss: 1.9077 - val_accuracy: 0.1667\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8796 - accuracy: 0.1731 - val_loss: 1.9071 - val_accuracy: 0.1667\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8802 - accuracy: 0.1731 - val_loss: 1.9063 - val_accuracy: 0.1667\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8816 - accuracy: 0.0962 - val_loss: 1.9072 - val_accuracy: 0.1667\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8829 - accuracy: 0.1731 - val_loss: 1.9078 - val_accuracy: 0.1667\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8833 - accuracy: 0.1731 - val_loss: 1.9076 - val_accuracy: 0.1667\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8837 - accuracy: 0.1731 - val_loss: 1.9064 - val_accuracy: 0.1667\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8837 - accuracy: 0.1731 - val_loss: 1.9032 - val_accuracy: 0.1667\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8804 - accuracy: 0.1731 - val_loss: 1.9025 - val_accuracy: 0.1667\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8820 - accuracy: 0.1731 - val_loss: 1.9036 - val_accuracy: 0.1667\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8818 - accuracy: 0.1731 - val_loss: 1.9057 - val_accuracy: 0.1667\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9076 - val_accuracy: 0.1667\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8807 - accuracy: 0.1731 - val_loss: 1.9094 - val_accuracy: 0.1667\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8865 - accuracy: 0.1731 - val_loss: 1.9116 - val_accuracy: 0.1667\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8806 - accuracy: 0.1731 - val_loss: 1.9087 - val_accuracy: 0.1667\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8802 - accuracy: 0.1731 - val_loss: 1.9057 - val_accuracy: 0.1667\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8807 - accuracy: 0.1731 - val_loss: 1.9032 - val_accuracy: 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8828 - accuracy: 0.1731 - val_loss: 1.9020 - val_accuracy: 0.1667\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8817 - accuracy: 0.1731 - val_loss: 1.9025 - val_accuracy: 0.1667\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8805 - accuracy: 0.1731 - val_loss: 1.9024 - val_accuracy: 0.1667\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8804 - accuracy: 0.1731 - val_loss: 1.9024 - val_accuracy: 0.1667\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8805 - accuracy: 0.1731 - val_loss: 1.9033 - val_accuracy: 0.1667\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8803 - accuracy: 0.1731 - val_loss: 1.9047 - val_accuracy: 0.1667\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8818 - accuracy: 0.1731 - val_loss: 1.9065 - val_accuracy: 0.1667\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8803 - accuracy: 0.1731 - val_loss: 1.9062 - val_accuracy: 0.1667\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8800 - accuracy: 0.1731 - val_loss: 1.9064 - val_accuracy: 0.1667\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8809 - accuracy: 0.1731 - val_loss: 1.9060 - val_accuracy: 0.1667\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8805 - accuracy: 0.1731 - val_loss: 1.9053 - val_accuracy: 0.1667\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8815 - accuracy: 0.1731 - val_loss: 1.9042 - val_accuracy: 0.1667\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8807 - accuracy: 0.1731 - val_loss: 1.9041 - val_accuracy: 0.1667\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8800 - accuracy: 0.1731 - val_loss: 1.9038 - val_accuracy: 0.1667\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8810 - accuracy: 0.1731 - val_loss: 1.9035 - val_accuracy: 0.1667\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "[['720,720', 1, 1.867696762084961, 0.1764705926179886], ['600,600', 2, 1.867264986038208, 0.1764705926179886], ['480,480', 3, 1.865319013595581, 0.1764705926179886], ['360,360', 4, 1.8659905195236206, 0.1764705926179886], ['240,240', 5, 1.8665239810943604, 0.1764705926179886], ['120,120', 6, 1.867735743522644, 0.1764705926179886]]\n",
      "Time elapsed:  492.20850110054016\n"
     ]
    }
   ],
   "source": [
    "summary, histories = start(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = histories[0]\n",
    "history2 = histories[1]\n",
    "history3 = histories[2]\n",
    "history4 = histories[3]\n",
    "history5 = histories[4]\n",
    "history6 = histories[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pp.plot_hist(history5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3be818beda55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ENB12_histories.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mhistories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "with open('ENB12_histories.txt', 'rb') as fp:\n",
    "    histories = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ENB12_results.txt', 'rb') as fp:\n",
    "    summary = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pp.results_to_df(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0  1  Test_Loss  Test_Accuracy\n",
      "5  120,120  6   1.867736       0.176471\n",
      "4  240,240  5   1.866524       0.176471\n",
      "3  360,360  4   1.865991       0.176471\n",
      "2  480,480  3   1.865319       0.176471\n",
      "1  600,600  2   1.867265       0.176471\n",
      "0  720,720  1   1.867697       0.176471\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
